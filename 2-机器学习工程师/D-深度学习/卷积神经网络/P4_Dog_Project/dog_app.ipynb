{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络（Convolutional Neural Network, CNN）\n",
    "\n",
    "## 项目：实现一个狗品种识别算法App\n",
    "\n",
    "在这个notebook文件中，有些模板代码已经提供给你，但你还需要实现更多的功能来完成这个项目。除非有明确要求，你无须修改任何已给出的代码。以**'(练习)'**开始的标题表示接下来的代码部分中有你需要实现的功能。这些部分都配有详细的指导，需要实现的部分也会在注释中以'TODO'标出。请仔细阅读所有的提示。\n",
    "\n",
    "除了实现代码外，你还**需要**回答一些与项目及代码相关的问题。每个需要回答的问题都会以 **'问题 X'** 标记。请仔细阅读每个问题，并且在问题后的 **'回答'** 部分写出完整的答案。我们将根据 你对问题的回答 和 撰写代码实现的功能 来对你提交的项目进行评分。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。\n",
    "\n",
    "项目中显示为_选做_的部分可以帮助你的项目脱颖而出，而不是仅仅达到通过的最低要求。如果你决定追求更高的挑战，请在此 notebook 中完成_选做_部分的代码。\n",
    "\n",
    "---\n",
    "\n",
    "### 让我们开始吧\n",
    "在这个notebook中，你将迈出第一步，来开发可以作为移动端或 Web应用程序一部分的算法。在这个项目的最后，你的程序将能够把用户提供的任何一个图像作为输入。如果可以从图像中检测到一只狗，它会输出对狗品种的预测。如果图像中是一个人脸，它会预测一个与其最相似的狗的种类。下面这张图展示了完成项目后可能的输出结果。（……实际上我们希望每个学生的输出结果不相同！）\n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "在现实世界中，你需要拼凑一系列的模型来完成不同的任务；举个例子，用来预测狗种类的算法会与预测人类的算法不同。在做项目的过程中，你可能会遇到不少失败的预测，因为并不存在完美的算法和模型。你最终提交的不完美的解决方案也一定会给你带来一个有趣的学习经验！\n",
    "\n",
    "### 项目内容\n",
    "\n",
    "我们将这个notebook分为不同的步骤，你可以使用下面的链接来浏览此notebook。\n",
    "\n",
    "* [Step 0](#step0): 导入数据集\n",
    "* [Step 1](#step1): 检测人脸\n",
    "* [Step 2](#step2): 检测狗狗\n",
    "* [Step 3](#step3): 从头创建一个CNN来分类狗品种\n",
    "* [Step 4](#step4): 使用一个CNN来区分狗的品种(使用迁移学习)\n",
    "* [Step 5](#step5): 建立一个CNN来分类狗的品种（使用迁移学习）\n",
    "* [Step 6](#step6): 完成你的算法\n",
    "* [Step 7](#step7): 测试你的算法\n",
    "\n",
    "在该项目中包含了如下的问题：\n",
    "\n",
    "* [问题 1](#question1)\n",
    "* [问题 2](#question2)\n",
    "* [问题 3](#question3)\n",
    "* [问题 4](#question4)\n",
    "* [问题 5](#question5)\n",
    "* [问题 6](#question6)\n",
    "* [问题 7](#question7)\n",
    "* [问题 8](#question8)\n",
    "* [问题 9](#question9)\n",
    "* [问题 10](#question10)\n",
    "* [问题 11](#question11)\n",
    "\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## 步骤 0: 导入数据集\n",
    "\n",
    "### 导入狗数据集\n",
    "在下方的代码单元（cell）中，我们导入了一个狗图像的数据集。我们使用 scikit-learn 库中的 `load_files` 函数来获取一些变量：\n",
    "- `train_files`, `valid_files`, `test_files` - 包含图像的文件路径的numpy数组\n",
    "- `train_targets`, `valid_targets`, `test_targets` - 包含独热编码分类标签的numpy数组\n",
    "- `dog_names` - 由字符串构成的与标签相对应的狗的种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconfig = tf.ConfigProto()\\nconfig.gpu_options.allow_growth = True      #程序按需申请内存\\nsess = tf.Session(config = config)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True      #程序按需申请内存\n",
    "sess = tf.Session(config = config)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入人脸数据集\n",
    "\n",
    "在下方的代码单元中，我们导入人脸图像数据集，文件所在路径存储在名为 `human_files` 的 numpy 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "# 加载打乱后的人脸数据集的文件名\n",
    "human_files = np.array(glob(\"lfw/*/*\"))\n",
    "random.shuffle(human_files)\n",
    "\n",
    "# 打印数据集的数据量\n",
    "print('There are %d total human images.' % len(human_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## 步骤1：检测人脸\n",
    " \n",
    "我们将使用 OpenCV 中的 [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) 来检测图像中的人脸。OpenCV 提供了很多预训练的人脸检测模型，它们以XML文件保存在 [github](https://github.com/opencv/opencv/tree/master/data/haarcascades)。我们已经下载了其中一个检测模型，并且把它存储在 `haarcascades` 的目录中。\n",
    "\n",
    "在如下代码单元中，我们将演示如何使用这个检测模型在样本图像中找到人脸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# 提取预训练的人脸检测模型\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# 加载彩色（通道顺序为BGR）图像\n",
    "img = cv2.imread(human_files[3])\n",
    "\n",
    "# 将BGR图像进行灰度处理\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 在图像中找出脸\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# 打印图像中检测到的脸的个数\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# 获取每一个所检测到的脸的识别框\n",
    "for (x,y,w,h) in faces:\n",
    "    # 在人脸图像中绘制出识别框\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# 将BGR图像转变为RGB图像以打印\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 展示含有识别框的图像\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用任何一个检测模型之前，将图像转换为灰度图是常用过程。`detectMultiScale` 函数使用储存在 `face_cascade` 中的的数据，对输入的灰度图像进行分类。\n",
    "\n",
    "在上方的代码中，`faces` 以 numpy 数组的形式，保存了识别到的面部信息。它其中每一行表示一个被检测到的脸，该数据包括如下四个信息：前两个元素  `x`、`y` 代表识别框左上角的 x 和 y 坐标（参照上图，注意 y 坐标的方向和我们默认的方向不同）；后两个元素代表识别框在 x 和 y 轴两个方向延伸的长度 `w` 和 `d`。 \n",
    "\n",
    "### 写一个人脸识别器\n",
    "\n",
    "我们可以将这个程序封装为一个函数。该函数的输入为人脸图像的**路径**，当图像中包含人脸时，该函数返回 `True`，反之返回 `False`。该函数定义如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果img_path路径表示的图像检测到了脸，返回\"True\" \n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【练习】** 评估人脸检测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='question1'></a>\n",
    "### __问题 1:__ \n",
    "\n",
    "在下方的代码块中，使用 `face_detector` 函数，计算：\n",
    "\n",
    "- `human_files` 的前100张图像中，能够检测到**人脸**的图像占比多少？\n",
    "- `dog_files` 的前100张图像中，能够检测到**人脸**的图像占比多少？\n",
    "\n",
    "理想情况下，人图像中检测到人脸的概率应当为100%，而狗图像中检测到人脸的概率应该为0%。你会发现我们的算法并非完美，但结果仍然是可以接受的。我们从每个数据集中提取前100个图像的文件路径，并将它们存储在`human_files_short`和`dog_files_short`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "human_files_short = human_files[:100]\n",
    "dog_files_short = train_files[:100]\n",
    "## 请不要修改上方代码\n",
    "def q1(files):\n",
    "    yes = 0\n",
    "    for i in files:\n",
    "        if face_detector(i):\n",
    "            yes += 1\n",
    "    return yes/len(files)\n",
    "\n",
    "print(q1(human_files_short))\n",
    "print(q1(dog_files_short))\n",
    "## TODO: 基于human_files_short和dog_files_short\n",
    "## 中的图像测试face_detector的表现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='question2'></a>\n",
    "\n",
    "### __问题 2:__ \n",
    "\n",
    "就算法而言，该算法成功与否的关键在于，用户能否提供含有清晰面部特征的人脸图像。\n",
    "那么你认为，这样的要求在实际使用中对用户合理吗？如果你觉得不合理，你能否想到一个方法，即使图像中并没有清晰的面部特征，也能够检测到人脸？\n",
    "\n",
    "__回答:__\n",
    "\n",
    "不合理，采用卷积网络算法来实现可能会更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Selection1'></a>\n",
    "### 选做：\n",
    "\n",
    "我们建议在你的算法中使用opencv的人脸检测模型去检测人类图像，不过你可以自由地探索其他的方法，尤其是尝试使用深度学习来解决它:)。请用下方的代码单元来设计和测试你的面部监测算法。如果你决定完成这个_选做_任务，你需要报告算法在每一个数据集上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "\n",
    "## 步骤 2: 检测狗狗\n",
    "\n",
    "在这个部分中，我们使用预训练的 [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) 模型去检测图像中的狗。下方的第一行代码就是下载了 ResNet-50 模型的网络结构参数，以及基于 [ImageNet](http://www.image-net.org/) 数据集的预训练权重。\n",
    "\n",
    "ImageNet 这目前一个非常流行的数据集，常被用来测试图像分类等计算机视觉任务相关的算法。它包含超过一千万个 URL，每一个都链接到 [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) 中所对应的一个物体的图像。任给输入一个图像，该 ResNet-50 模型会返回一个对图像中物体的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# 定义ResNet50模型\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "- 在使用 TensorFlow 作为后端的时候，在 Keras 中，CNN 的输入是一个4维数组（也被称作4维张量），它的各维度尺寸为 `(nb_samples, rows, columns, channels)`。其中 `nb_samples` 表示图像（或者样本）的总数，`rows`, `columns`, 和 `channels` 分别表示图像的行数、列数和通道数。\n",
    "\n",
    "\n",
    "- 下方的 `path_to_tensor` 函数实现如下将彩色图像的字符串型的文件路径作为输入，返回一个4维张量，作为 Keras CNN 输入。因为我们的输入图像是彩色图像，因此它们具有三个通道（ `channels` 为 `3`）。\n",
    "    1. 该函数首先读取一张图像，然后将其缩放为 224×224 的图像。\n",
    "    2. 随后，该图像被调整为具有4个维度的张量。\n",
    "    3. 对于任一输入图像，最后返回的张量的维度是：`(1, 224, 224, 3)`。\n",
    "\n",
    "\n",
    "- `paths_to_tensor` 函数将图像路径的字符串组成的 numpy 数组作为输入，并返回一个4维张量，各维度尺寸为 `(nb_samples, 224, 224, 3)`。 在这里，`nb_samples`是提供的图像路径的数据中的样本数量或图像数量。你也可以将 `nb_samples` 理解为数据集中3维张量的个数（每个3维张量表示一个不同的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 ResNet-50 架构进行预测\n",
    "\n",
    "对于通过上述步骤得到的四维张量，在把它们输入到 ResNet-50 网络、或 Keras 中其他类似的预训练模型之前，还需要进行一些额外的处理：\n",
    "1. 首先，这些图像的通道顺序为 RGB，我们需要重排他们的通道顺序为 BGR。\n",
    "2. 其次，预训练模型的输入都进行了额外的归一化过程。因此我们在这里也要对这些张量进行归一化，即对所有图像所有像素都减去像素均值 `[103.939, 116.779, 123.68]`（以 RGB 模式表示，根据所有的 ImageNet 图像算出）。\n",
    "\n",
    "导入的 `preprocess_input` 函数实现了这些功能。如果你对此很感兴趣，可以在 [这里](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py) 查看 `preprocess_input`的代码。\n",
    "\n",
    "\n",
    "在实现了图像处理的部分之后，我们就可以使用模型来进行预测。这一步通过 `predict` 方法来实现，它返回一个向量，向量的第 i 个元素表示该图像属于第 i 个 ImageNet 类别的概率。这通过如下的 `ResNet50_predict_labels` 函数实现。\n",
    "\n",
    "通过对预测出的向量取用 argmax 函数（找到有最大概率值的下标序号），我们可以得到一个整数，即模型预测到的物体的类别。进而根据这个 [清单](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)，我们能够知道这具体是哪个品种的狗狗。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # 返回img_path路径的图像的预测向量\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完成狗检测模型\n",
    "\n",
    "\n",
    "在研究该 [清单](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) 的时候，你会注意到，狗类别对应的序号为151-268。因此，在检查预训练模型判断图像是否包含狗的时候，我们只需要检查如上的 `ResNet50_predict_labels` 函数是否返回一个介于151和268之间（包含区间端点）的值。\n",
    "\n",
    "我们通过这些想法来完成下方的 `dog_detector` 函数，如果从图像中检测到狗就返回 `True`，否则返回 `False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【作业】评估狗狗检测模型\n",
    "\n",
    "---\n",
    "\n",
    "<a id='question3'></a>\n",
    "### __问题 3:__ \n",
    "\n",
    "在下方的代码块中，使用 `dog_detector` 函数，计算：\n",
    "\n",
    "- `human_files_short`中图像检测到狗狗的百分比？\n",
    "- `dog_files_short`中图像检测到狗狗的百分比？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "### TODO: 测试dog_detector函数在human_files_short和dog_files_short的表现\n",
    "\n",
    "def q3(files):\n",
    "    is_dog = 0\n",
    "    for img in files:\n",
    "        if dog_detector(img):\n",
    "            is_dog += 1\n",
    "    return is_dog/len(files)\n",
    "\n",
    "print(q3(human_files_short))\n",
    "print(q3(dog_files_short))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='step3'></a>\n",
    "\n",
    "## 步骤 3: 从头开始创建一个CNN来分类狗品种\n",
    "\n",
    "\n",
    "现在我们已经实现了一个函数，能够在图像中识别人类及狗狗。但我们需要更进一步的方法，来对狗的类别进行识别。在这一步中，你需要实现一个卷积神经网络来对狗的品种进行分类。你需要__从头实现__你的卷积神经网络（在这一阶段，你还不能使用迁移学习），并且你需要达到超过1%的测试集准确率。在本项目的步骤五种，你还有机会使用迁移学习来实现一个准确率大大提高的模型。\n",
    "\n",
    "在添加卷积层的时候，注意不要加上太多的（可训练的）层。更多的参数意味着更长的训练时间，也就是说你更可能需要一个 GPU 来加速训练过程。万幸的是，Keras 提供了能够轻松预测每次迭代（epoch）花费时间所需的函数。你可以据此推断你算法所需的训练时间。\n",
    "\n",
    "值得注意的是，对狗的图像进行分类是一项极具挑战性的任务。因为即便是一个正常人，也很难区分布列塔尼犬和威尔士史宾格犬。\n",
    "\n",
    "\n",
    "布列塔尼犬（Brittany） | 威尔士史宾格犬（Welsh Springer Spaniel）\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "不难发现其他的狗品种会有很小的类间差别（比如金毛寻回犬和美国水猎犬）。\n",
    "\n",
    "\n",
    "金毛寻回犬（Curly-Coated Retriever） | 美国水猎犬（American Water Spaniel）\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "同样，拉布拉多犬（labradors）有黄色、棕色和黑色这三种。那么你设计的基于视觉的算法将不得不克服这种较高的类间差别，以达到能够将这些不同颜色的同类狗分到同一个品种中。\n",
    "\n",
    "黄色拉布拉多犬（Yellow Labrador） | 棕色拉布拉多犬（Chocolate Labrador） | 黑色拉布拉多犬（Black Labrador）\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "我们也提到了随机分类将得到一个非常低的结果：不考虑品种略有失衡的影响，随机猜测到正确品种的概率是1/133，相对应的准确率是低于1%的。\n",
    "\n",
    "请记住，在深度学习领域，实践远远高于理论。大量尝试不同的框架吧，相信你的直觉！当然，玩得开心！\n",
    "\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "\n",
    "通过对每张图像的像素值除以255，我们对图像实现了归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6680/6680 [00:48<00:00, 139.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 835/835 [00:11<00:00, 74.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 836/836 [00:05<00:00, 147.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# Keras中的数据预处理过程\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【练习】模型架构\n",
    "\n",
    "\n",
    "创建一个卷积神经网络来对狗品种进行分类。在你代码块的最后，执行 `model.summary()` 来输出你模型的总结信息。\n",
    "    \n",
    "我们已经帮你导入了一些所需的 Python 库，如有需要你可以自行导入。如果你在过程中遇到了困难，如下是给你的一点小提示——该模型能够在5个 epoch 内取得超过1%的测试准确率，并且能在CPU上很快地训练。\n",
    "\n",
    "![Sample CNN](images/sample_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='question4'></a>  \n",
    "\n",
    "### __问题 4:__ \n",
    "\n",
    "在下方的代码块中尝试使用 Keras 搭建卷积网络的架构，并回答相关的问题。\n",
    "\n",
    "1. 你可以尝试自己搭建一个卷积网络的模型，那么你需要回答你搭建卷积网络的具体步骤（用了哪些层）以及为什么这样搭建。\n",
    "2. 你也可以根据上图提示的步骤搭建卷积网络，那么请说明为何如上的架构能够在该问题上取得很好的表现。\n",
    "\n",
    "__回答:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               8645      \n",
      "=================================================================\n",
      "Total params: 19,189\n",
      "Trainable params: 19,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "### TODO: 定义你的网络架构\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(133))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 编译模型\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【练习】训练模型\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<a id='question5'></a>  \n",
    "\n",
    "### __问题 5:__ \n",
    "\n",
    "在下方代码单元训练模型。使用模型检查点（model checkpointing）来储存具有最低验证集 loss 的模型。\n",
    "\n",
    "可选题：你也可以对训练集进行 [数据增强](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)，来优化模型的表现。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n###################可选题#################\\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\\nbatch_size = 16\\ntrain_datagen = ImageDataGenerator(\\n        rescale=1./255,\\n        shear_range=0.2,\\n        zoom_range=0.2,\\n        horizontal_flip=True)\\n\\n# this is the augmentation configuration we will use for testing:\\n# only rescaling\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\n\\n# this is a generator that will read pictures found in\\n# subfolers of 'data/train', and indefinitely generate\\n# batches of augmented image data\\n\\ntrain_generator = train_datagen.flow_from_directory(\\n        'dogImages/train',  # this is the target directory\\n        target_size=(223, 223),  # all images will be resized to 150x150\\n        batch_size=batch_size,\\n        )  # since we use binary_crossentropy loss, we need binary labels\\n\\n# this is a similar generator, for validation data\\nvalidation_generator = test_datagen.flow_from_directory(\\n        'dogImages/valid',\\n        target_size=(223, 223),\\n        batch_size=batch_size,\\n        )\\n        \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "###################可选题#################\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dogImages/train',  # this is the target directory\n",
    "        target_size=(223, 223),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        )  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'dogImages/valid',\n",
    "        target_size=(223, 223),\n",
    "        batch_size=batch_size,\n",
    "        )\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/10\n",
      "6680/6680 [==============================] - ETA: 5:29 - loss: 8.5856 - acc: 0.0000e+0 - ETA: 1:27 - loss: 7.8897 - acc: 0.0000e+0 - ETA: 52s - loss: 8.1071 - acc: 0.0000e+0 - ETA: 38s - loss: 8.1060 - acc: 0.0100   - ETA: 30s - loss: 8.4616 - acc: 0.00 - ETA: 26s - loss: 8.4117 - acc: 0.00 - ETA: 22s - loss: 8.5601 - acc: 0.00 - ETA: 20s - loss: 8.5248 - acc: 0.00 - ETA: 18s - loss: 8.6538 - acc: 0.00 - ETA: 17s - loss: 8.6743 - acc: 0.00 - ETA: 15s - loss: 8.6478 - acc: 0.00 - ETA: 14s - loss: 8.6988 - acc: 0.00 - ETA: 14s - loss: 8.6718 - acc: 0.00 - ETA: 13s - loss: 8.6526 - acc: 0.00 - ETA: 12s - loss: 8.6793 - acc: 0.00 - ETA: 12s - loss: 8.6000 - acc: 0.00 - ETA: 11s - loss: 8.6731 - acc: 0.00 - ETA: 11s - loss: 8.6489 - acc: 0.00 - ETA: 10s - loss: 8.7439 - acc: 0.00 - ETA: 10s - loss: 8.6487 - acc: 0.00 - ETA: 10s - loss: 8.6590 - acc: 0.00 - ETA: 9s - loss: 8.6803 - acc: 0.0047 - ETA: 9s - loss: 8.6618 - acc: 0.004 - ETA: 9s - loss: 8.5861 - acc: 0.004 - ETA: 8s - loss: 8.6238 - acc: 0.005 - ETA: 8s - loss: 8.5663 - acc: 0.005 - ETA: 8s - loss: 8.6302 - acc: 0.005 - ETA: 8s - loss: 8.6053 - acc: 0.004 - ETA: 8s - loss: 8.5871 - acc: 0.004 - ETA: 7s - loss: 8.6132 - acc: 0.004 - ETA: 7s - loss: 8.6575 - acc: 0.004 - ETA: 7s - loss: 8.6386 - acc: 0.004 - ETA: 7s - loss: 8.6560 - acc: 0.004 - ETA: 7s - loss: 8.6661 - acc: 0.004 - ETA: 7s - loss: 8.6529 - acc: 0.004 - ETA: 6s - loss: 8.6427 - acc: 0.004 - ETA: 6s - loss: 8.6390 - acc: 0.004 - ETA: 6s - loss: 8.6413 - acc: 0.004 - ETA: 6s - loss: 8.6022 - acc: 0.004 - ETA: 6s - loss: 8.5702 - acc: 0.004 - ETA: 6s - loss: 8.5475 - acc: 0.004 - ETA: 6s - loss: 8.5336 - acc: 0.004 - ETA: 5s - loss: 8.5138 - acc: 0.004 - ETA: 5s - loss: 8.5114 - acc: 0.004 - ETA: 5s - loss: 8.5351 - acc: 0.004 - ETA: 5s - loss: 8.5249 - acc: 0.004 - ETA: 5s - loss: 8.5407 - acc: 0.004 - ETA: 5s - loss: 8.5101 - acc: 0.004 - ETA: 5s - loss: 8.5399 - acc: 0.005 - ETA: 5s - loss: 8.5461 - acc: 0.005 - ETA: 5s - loss: 8.5584 - acc: 0.005 - ETA: 4s - loss: 8.5563 - acc: 0.005 - ETA: 4s - loss: 8.5772 - acc: 0.005 - ETA: 4s - loss: 8.6054 - acc: 0.005 - ETA: 4s - loss: 8.6034 - acc: 0.004 - ETA: 4s - loss: 8.6075 - acc: 0.004 - ETA: 4s - loss: 8.6046 - acc: 0.004 - ETA: 4s - loss: 8.6151 - acc: 0.004 - ETA: 4s - loss: 8.6038 - acc: 0.004 - ETA: 4s - loss: 8.6114 - acc: 0.004 - ETA: 4s - loss: 8.5929 - acc: 0.004 - ETA: 3s - loss: 8.6004 - acc: 0.004 - ETA: 3s - loss: 8.6147 - acc: 0.004 - ETA: 3s - loss: 8.5981 - acc: 0.004 - ETA: 3s - loss: 8.6029 - acc: 0.004 - ETA: 3s - loss: 8.6112 - acc: 0.004 - ETA: 3s - loss: 8.5954 - acc: 0.004 - ETA: 3s - loss: 8.5967 - acc: 0.004 - ETA: 3s - loss: 8.5919 - acc: 0.004 - ETA: 3s - loss: 8.5797 - acc: 0.004 - ETA: 3s - loss: 8.5724 - acc: 0.004 - ETA: 3s - loss: 8.5730 - acc: 0.004 - ETA: 2s - loss: 8.5870 - acc: 0.004 - ETA: 2s - loss: 8.5884 - acc: 0.004 - ETA: 2s - loss: 8.5946 - acc: 0.004 - ETA: 2s - loss: 8.5905 - acc: 0.005 - ETA: 2s - loss: 8.5876 - acc: 0.005 - ETA: 2s - loss: 8.5732 - acc: 0.005 - ETA: 2s - loss: 8.5679 - acc: 0.004 - ETA: 2s - loss: 8.5661 - acc: 0.004 - ETA: 2s - loss: 8.5521 - acc: 0.005 - ETA: 2s - loss: 8.5619 - acc: 0.004 - ETA: 2s - loss: 8.5825 - acc: 0.005 - ETA: 2s - loss: 8.6096 - acc: 0.005 - ETA: 1s - loss: 8.6236 - acc: 0.005 - ETA: 1s - loss: 8.6217 - acc: 0.005 - ETA: 1s - loss: 8.6224 - acc: 0.005 - ETA: 1s - loss: 8.6141 - acc: 0.005 - ETA: 1s - loss: 8.5969 - acc: 0.005 - ETA: 1s - loss: 8.5837 - acc: 0.005 - ETA: 1s - loss: 8.5932 - acc: 0.005 - ETA: 1s - loss: 8.5944 - acc: 0.005 - ETA: 1s - loss: 8.5949 - acc: 0.005 - ETA: 1s - loss: 8.5959 - acc: 0.005 - ETA: 1s - loss: 8.5913 - acc: 0.005 - ETA: 1s - loss: 8.5885 - acc: 0.005 - ETA: 1s - loss: 8.6032 - acc: 0.005 - ETA: 1s - loss: 8.6082 - acc: 0.005 - ETA: 0s - loss: 8.6013 - acc: 0.005 - ETA: 0s - loss: 8.5888 - acc: 0.005 - ETA: 0s - loss: 8.5928 - acc: 0.005 - ETA: 0s - loss: 8.6006 - acc: 0.005 - ETA: 0s - loss: 8.5930 - acc: 0.005 - ETA: 0s - loss: 8.5723 - acc: 0.005 - ETA: 0s - loss: 8.5714 - acc: 0.005 - ETA: 0s - loss: 8.5606 - acc: 0.005 - ETA: 0s - loss: 8.5648 - acc: 0.005 - ETA: 0s - loss: 8.5668 - acc: 0.005 - ETA: 0s - loss: 8.5576 - acc: 0.005 - ETA: 0s - loss: 8.5452 - acc: 0.005 - ETA: 0s - loss: 8.5474 - acc: 0.005 - 9s 1ms/step - loss: 8.5600 - acc: 0.0057 - val_loss: 9.3094 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.30940, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 10.6378 - acc: 0.0000e+ - ETA: 6s - loss: 8.6666 - acc: 0.0125     - ETA: 6s - loss: 8.4119 - acc: 0.014 - ETA: 6s - loss: 8.2749 - acc: 0.010 - ETA: 6s - loss: 8.5648 - acc: 0.011 - ETA: 6s - loss: 8.5615 - acc: 0.015 - ETA: 6s - loss: 8.4831 - acc: 0.013 - ETA: 6s - loss: 8.7701 - acc: 0.011 - ETA: 6s - loss: 8.7771 - acc: 0.010 - ETA: 6s - loss: 8.4608 - acc: 0.008 - ETA: 6s - loss: 8.4140 - acc: 0.009 - ETA: 6s - loss: 8.4265 - acc: 0.008 - ETA: 6s - loss: 8.3465 - acc: 0.008 - ETA: 6s - loss: 8.4093 - acc: 0.007 - ETA: 6s - loss: 8.3785 - acc: 0.008 - ETA: 6s - loss: 8.4211 - acc: 0.007 - ETA: 5s - loss: 8.4396 - acc: 0.007 - ETA: 5s - loss: 8.3874 - acc: 0.009 - ETA: 5s - loss: 8.3722 - acc: 0.010 - ETA: 5s - loss: 8.4090 - acc: 0.009 - ETA: 5s - loss: 8.3776 - acc: 0.009 - ETA: 5s - loss: 8.3392 - acc: 0.008 - ETA: 5s - loss: 8.3447 - acc: 0.008 - ETA: 5s - loss: 8.2933 - acc: 0.008 - ETA: 5s - loss: 8.3242 - acc: 0.008 - ETA: 5s - loss: 8.2834 - acc: 0.010 - ETA: 5s - loss: 8.3034 - acc: 0.011 - ETA: 5s - loss: 8.2518 - acc: 0.011 - ETA: 5s - loss: 8.2220 - acc: 0.011 - ETA: 5s - loss: 8.2253 - acc: 0.010 - ETA: 5s - loss: 8.2300 - acc: 0.011 - ETA: 5s - loss: 8.2544 - acc: 0.011 - ETA: 4s - loss: 8.2903 - acc: 0.011 - ETA: 4s - loss: 8.3429 - acc: 0.011 - ETA: 4s - loss: 8.3304 - acc: 0.011 - ETA: 4s - loss: 8.3265 - acc: 0.011 - ETA: 4s - loss: 8.3297 - acc: 0.011 - ETA: 4s - loss: 8.3945 - acc: 0.011 - ETA: 4s - loss: 8.3648 - acc: 0.010 - ETA: 4s - loss: 8.3905 - acc: 0.011 - ETA: 4s - loss: 8.3692 - acc: 0.011 - ETA: 4s - loss: 8.3832 - acc: 0.010 - ETA: 4s - loss: 8.3948 - acc: 0.010 - ETA: 4s - loss: 8.3470 - acc: 0.010 - ETA: 4s - loss: 8.3368 - acc: 0.010 - ETA: 4s - loss: 8.3299 - acc: 0.010 - ETA: 4s - loss: 8.2925 - acc: 0.010 - ETA: 4s - loss: 8.3017 - acc: 0.010 - ETA: 3s - loss: 8.3294 - acc: 0.010 - ETA: 3s - loss: 8.3708 - acc: 0.010 - ETA: 3s - loss: 8.3491 - acc: 0.009 - ETA: 3s - loss: 8.3174 - acc: 0.009 - ETA: 3s - loss: 8.3357 - acc: 0.009 - ETA: 3s - loss: 8.3181 - acc: 0.010 - ETA: 3s - loss: 8.3189 - acc: 0.009 - ETA: 3s - loss: 8.3034 - acc: 0.009 - ETA: 3s - loss: 8.2989 - acc: 0.009 - ETA: 3s - loss: 8.2854 - acc: 0.009 - ETA: 3s - loss: 8.2997 - acc: 0.009 - ETA: 3s - loss: 8.3052 - acc: 0.009 - ETA: 3s - loss: 8.3111 - acc: 0.009 - ETA: 3s - loss: 8.3291 - acc: 0.009 - ETA: 3s - loss: 8.3279 - acc: 0.009 - ETA: 3s - loss: 8.3314 - acc: 0.008 - ETA: 2s - loss: 8.3584 - acc: 0.008 - ETA: 2s - loss: 8.3364 - acc: 0.008 - ETA: 2s - loss: 8.3478 - acc: 0.008 - ETA: 2s - loss: 8.3531 - acc: 0.008 - ETA: 2s - loss: 8.3631 - acc: 0.008 - ETA: 2s - loss: 8.3365 - acc: 0.008 - ETA: 2s - loss: 8.3581 - acc: 0.008 - ETA: 2s - loss: 8.3460 - acc: 0.008 - ETA: 2s - loss: 8.3568 - acc: 0.008 - ETA: 2s - loss: 8.3395 - acc: 0.008 - ETA: 2s - loss: 8.3072 - acc: 0.008 - ETA: 2s - loss: 8.3280 - acc: 0.008 - ETA: 2s - loss: 8.3046 - acc: 0.008 - ETA: 2s - loss: 8.3215 - acc: 0.008 - ETA: 2s - loss: 8.3222 - acc: 0.008 - ETA: 2s - loss: 8.3161 - acc: 0.008 - ETA: 1s - loss: 8.3126 - acc: 0.008 - ETA: 1s - loss: 8.2829 - acc: 0.008 - ETA: 1s - loss: 8.2891 - acc: 0.008 - ETA: 1s - loss: 8.2971 - acc: 0.008 - ETA: 1s - loss: 8.2947 - acc: 0.008 - ETA: 1s - loss: 8.3016 - acc: 0.008 - ETA: 1s - loss: 8.3034 - acc: 0.008 - ETA: 1s - loss: 8.3025 - acc: 0.008 - ETA: 1s - loss: 8.3024 - acc: 0.008 - ETA: 1s - loss: 8.2975 - acc: 0.008 - ETA: 1s - loss: 8.3047 - acc: 0.008 - ETA: 1s - loss: 8.3018 - acc: 0.008 - ETA: 1s - loss: 8.2913 - acc: 0.008 - ETA: 1s - loss: 8.2875 - acc: 0.008 - ETA: 1s - loss: 8.2852 - acc: 0.008 - ETA: 1s - loss: 8.2877 - acc: 0.008 - ETA: 0s - loss: 8.2872 - acc: 0.008 - ETA: 0s - loss: 8.2868 - acc: 0.008 - ETA: 0s - loss: 8.2995 - acc: 0.008 - ETA: 0s - loss: 8.2950 - acc: 0.008 - ETA: 0s - loss: 8.2964 - acc: 0.008 - ETA: 0s - loss: 8.2822 - acc: 0.008 - ETA: 0s - loss: 8.2904 - acc: 0.008 - ETA: 0s - loss: 8.2900 - acc: 0.008 - ETA: 0s - loss: 8.2899 - acc: 0.008 - ETA: 0s - loss: 8.2753 - acc: 0.007 - ETA: 0s - loss: 8.2581 - acc: 0.008 - ETA: 0s - loss: 8.2471 - acc: 0.007 - ETA: 0s - loss: 8.2555 - acc: 0.007 - ETA: 0s - loss: 8.2591 - acc: 0.007 - ETA: 0s - loss: 8.2595 - acc: 0.007 - 7s 1ms/step - loss: 8.2635 - acc: 0.0078 - val_loss: 8.3969 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00002: val_loss improved from 9.30940 to 8.39691, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 7s - loss: 11.6914 - acc: 0.10 - ETA: 7s - loss: 11.2098 - acc: 0.03 - ETA: 7s - loss: 8.9879 - acc: 0.0214 - ETA: 6s - loss: 9.2849 - acc: 0.015 - ETA: 6s - loss: 8.9137 - acc: 0.011 - ETA: 6s - loss: 9.0026 - acc: 0.012 - ETA: 6s - loss: 8.8196 - acc: 0.013 - ETA: 6s - loss: 8.6475 - acc: 0.011 - ETA: 6s - loss: 8.5596 - acc: 0.010 - ETA: 6s - loss: 8.4470 - acc: 0.008 - ETA: 6s - loss: 8.4218 - acc: 0.008 - ETA: 6s - loss: 8.3661 - acc: 0.007 - ETA: 6s - loss: 8.4770 - acc: 0.006 - ETA: 6s - loss: 8.4484 - acc: 0.008 - ETA: 6s - loss: 8.4851 - acc: 0.009 - ETA: 6s - loss: 8.4581 - acc: 0.008 - ETA: 5s - loss: 8.4060 - acc: 0.008 - ETA: 5s - loss: 8.3827 - acc: 0.007 - ETA: 5s - loss: 8.3298 - acc: 0.008 - ETA: 5s - loss: 8.3712 - acc: 0.007 - ETA: 5s - loss: 8.3619 - acc: 0.007 - ETA: 5s - loss: 8.3561 - acc: 0.007 - ETA: 5s - loss: 8.3939 - acc: 0.006 - ETA: 5s - loss: 8.4381 - acc: 0.006 - ETA: 5s - loss: 8.4241 - acc: 0.006 - ETA: 5s - loss: 8.3607 - acc: 0.006 - ETA: 5s - loss: 8.3854 - acc: 0.007 - ETA: 5s - loss: 8.4418 - acc: 0.006 - ETA: 5s - loss: 8.3979 - acc: 0.006 - ETA: 5s - loss: 8.3596 - acc: 0.006 - ETA: 5s - loss: 8.3112 - acc: 0.007 - ETA: 5s - loss: 8.3398 - acc: 0.007 - ETA: 4s - loss: 8.2913 - acc: 0.007 - ETA: 4s - loss: 8.2920 - acc: 0.007 - ETA: 4s - loss: 8.3440 - acc: 0.006 - ETA: 4s - loss: 8.3540 - acc: 0.006 - ETA: 4s - loss: 8.3240 - acc: 0.006 - ETA: 4s - loss: 8.3363 - acc: 0.007 - ETA: 4s - loss: 8.3500 - acc: 0.007 - ETA: 4s - loss: 8.3595 - acc: 0.006 - ETA: 4s - loss: 8.3189 - acc: 0.006 - ETA: 4s - loss: 8.3242 - acc: 0.006 - ETA: 4s - loss: 8.3168 - acc: 0.006 - ETA: 4s - loss: 8.3167 - acc: 0.006 - ETA: 4s - loss: 8.3097 - acc: 0.006 - ETA: 4s - loss: 8.3487 - acc: 0.005 - ETA: 4s - loss: 8.3170 - acc: 0.005 - ETA: 3s - loss: 8.2891 - acc: 0.005 - ETA: 3s - loss: 8.3136 - acc: 0.005 - ETA: 3s - loss: 8.2789 - acc: 0.005 - ETA: 3s - loss: 8.2630 - acc: 0.006 - ETA: 3s - loss: 8.2323 - acc: 0.005 - ETA: 3s - loss: 8.2474 - acc: 0.006 - ETA: 3s - loss: 8.2294 - acc: 0.006 - ETA: 3s - loss: 8.2295 - acc: 0.006 - ETA: 3s - loss: 8.2047 - acc: 0.006 - ETA: 3s - loss: 8.2126 - acc: 0.006 - ETA: 3s - loss: 8.2151 - acc: 0.006 - ETA: 3s - loss: 8.2418 - acc: 0.006 - ETA: 3s - loss: 8.2407 - acc: 0.006 - ETA: 3s - loss: 8.2151 - acc: 0.006 - ETA: 3s - loss: 8.2447 - acc: 0.006 - ETA: 3s - loss: 8.2383 - acc: 0.006 - ETA: 3s - loss: 8.2252 - acc: 0.006 - ETA: 2s - loss: 8.2214 - acc: 0.006 - ETA: 2s - loss: 8.2070 - acc: 0.006 - ETA: 2s - loss: 8.2083 - acc: 0.006 - ETA: 2s - loss: 8.2032 - acc: 0.006 - ETA: 2s - loss: 8.2143 - acc: 0.006 - ETA: 2s - loss: 8.1982 - acc: 0.006 - ETA: 2s - loss: 8.1850 - acc: 0.006 - ETA: 2s - loss: 8.1749 - acc: 0.006 - ETA: 2s - loss: 8.1738 - acc: 0.006 - ETA: 2s - loss: 8.1466 - acc: 0.006 - ETA: 2s - loss: 8.1381 - acc: 0.006 - ETA: 2s - loss: 8.1369 - acc: 0.006 - ETA: 2s - loss: 8.1410 - acc: 0.006 - ETA: 2s - loss: 8.1599 - acc: 0.006 - ETA: 2s - loss: 8.1473 - acc: 0.006 - ETA: 1s - loss: 8.1406 - acc: 0.006 - ETA: 1s - loss: 8.1363 - acc: 0.006 - ETA: 1s - loss: 8.1299 - acc: 0.005 - ETA: 1s - loss: 8.1344 - acc: 0.006 - ETA: 1s - loss: 8.1460 - acc: 0.006 - ETA: 1s - loss: 8.1478 - acc: 0.006 - ETA: 1s - loss: 8.1359 - acc: 0.006 - ETA: 1s - loss: 8.1490 - acc: 0.006 - ETA: 1s - loss: 8.1440 - acc: 0.005 - ETA: 1s - loss: 8.1388 - acc: 0.005 - ETA: 1s - loss: 8.1323 - acc: 0.005 - ETA: 1s - loss: 8.1203 - acc: 0.005 - ETA: 1s - loss: 8.1155 - acc: 0.005 - ETA: 1s - loss: 8.1217 - acc: 0.006 - ETA: 1s - loss: 8.1312 - acc: 0.005 - ETA: 1s - loss: 8.1447 - acc: 0.005 - ETA: 0s - loss: 8.1639 - acc: 0.005 - ETA: 0s - loss: 8.1692 - acc: 0.005 - ETA: 0s - loss: 8.1710 - acc: 0.005 - ETA: 0s - loss: 8.1766 - acc: 0.005 - ETA: 0s - loss: 8.1767 - acc: 0.005 - ETA: 0s - loss: 8.1722 - acc: 0.005 - ETA: 0s - loss: 8.1694 - acc: 0.005 - ETA: 0s - loss: 8.1516 - acc: 0.005 - ETA: 0s - loss: 8.1473 - acc: 0.005 - ETA: 0s - loss: 8.1339 - acc: 0.005 - ETA: 0s - loss: 8.1322 - acc: 0.005 - ETA: 0s - loss: 8.1536 - acc: 0.005 - ETA: 0s - loss: 8.1589 - acc: 0.005 - ETA: 0s - loss: 8.1666 - acc: 0.005 - ETA: 0s - loss: 8.1623 - acc: 0.005 - ETA: 0s - loss: 8.1493 - acc: 0.005 - 7s 1ms/step - loss: 8.1459 - acc: 0.0058 - val_loss: 8.1076 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00003: val_loss improved from 8.39691 to 8.10759, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 7s - loss: 9.2754 - acc: 0.0000e+0 - ETA: 7s - loss: 9.5778 - acc: 0.0125    - ETA: 7s - loss: 8.8268 - acc: 0.014 - ETA: 6s - loss: 9.0624 - acc: 0.010 - ETA: 6s - loss: 9.0546 - acc: 0.015 - ETA: 6s - loss: 8.4832 - acc: 0.015 - ETA: 6s - loss: 8.6123 - acc: 0.013 - ETA: 6s - loss: 8.5190 - acc: 0.011 - ETA: 6s - loss: 8.5804 - acc: 0.012 - ETA: 6s - loss: 8.5413 - acc: 0.010 - ETA: 6s - loss: 8.6080 - acc: 0.009 - ETA: 6s - loss: 8.7107 - acc: 0.008 - ETA: 6s - loss: 8.6089 - acc: 0.009 - ETA: 6s - loss: 8.5959 - acc: 0.010 - ETA: 6s - loss: 8.6098 - acc: 0.009 - ETA: 6s - loss: 8.6287 - acc: 0.009 - ETA: 5s - loss: 8.6035 - acc: 0.009 - ETA: 5s - loss: 8.5520 - acc: 0.008 - ETA: 5s - loss: 8.5278 - acc: 0.009 - ETA: 5s - loss: 8.5062 - acc: 0.008 - ETA: 5s - loss: 8.4080 - acc: 0.008 - ETA: 5s - loss: 8.3693 - acc: 0.007 - ETA: 5s - loss: 8.2819 - acc: 0.007 - ETA: 5s - loss: 8.2480 - acc: 0.007 - ETA: 5s - loss: 8.1942 - acc: 0.007 - ETA: 5s - loss: 8.1521 - acc: 0.007 - ETA: 5s - loss: 8.1623 - acc: 0.007 - ETA: 5s - loss: 8.1714 - acc: 0.007 - ETA: 5s - loss: 8.1528 - acc: 0.007 - ETA: 5s - loss: 8.1782 - acc: 0.007 - ETA: 5s - loss: 8.2207 - acc: 0.007 - ETA: 5s - loss: 8.2289 - acc: 0.007 - ETA: 4s - loss: 8.2527 - acc: 0.007 - ETA: 4s - loss: 8.2532 - acc: 0.007 - ETA: 4s - loss: 8.2599 - acc: 0.007 - ETA: 4s - loss: 8.1822 - acc: 0.007 - ETA: 4s - loss: 8.1997 - acc: 0.006 - ETA: 4s - loss: 8.1694 - acc: 0.006 - ETA: 4s - loss: 8.1559 - acc: 0.006 - ETA: 4s - loss: 8.1754 - acc: 0.006 - ETA: 4s - loss: 8.2258 - acc: 0.006 - ETA: 4s - loss: 8.2286 - acc: 0.006 - ETA: 4s - loss: 8.1714 - acc: 0.006 - ETA: 4s - loss: 8.1590 - acc: 0.006 - ETA: 4s - loss: 8.1587 - acc: 0.007 - ETA: 4s - loss: 8.1458 - acc: 0.007 - ETA: 4s - loss: 8.1450 - acc: 0.007 - ETA: 4s - loss: 8.1432 - acc: 0.007 - ETA: 3s - loss: 8.1625 - acc: 0.007 - ETA: 3s - loss: 8.1670 - acc: 0.007 - ETA: 3s - loss: 8.1523 - acc: 0.007 - ETA: 3s - loss: 8.1288 - acc: 0.007 - ETA: 3s - loss: 8.1390 - acc: 0.007 - ETA: 3s - loss: 8.1188 - acc: 0.007 - ETA: 3s - loss: 8.1102 - acc: 0.007 - ETA: 3s - loss: 8.0963 - acc: 0.006 - ETA: 3s - loss: 8.0885 - acc: 0.007 - ETA: 3s - loss: 8.1240 - acc: 0.007 - ETA: 3s - loss: 8.1456 - acc: 0.007 - ETA: 3s - loss: 8.1749 - acc: 0.007 - ETA: 3s - loss: 8.1768 - acc: 0.007 - ETA: 3s - loss: 8.1797 - acc: 0.007 - ETA: 3s - loss: 8.1836 - acc: 0.007 - ETA: 3s - loss: 8.1897 - acc: 0.007 - ETA: 2s - loss: 8.1908 - acc: 0.007 - ETA: 2s - loss: 8.1898 - acc: 0.007 - ETA: 2s - loss: 8.1988 - acc: 0.007 - ETA: 2s - loss: 8.2011 - acc: 0.007 - ETA: 2s - loss: 8.1927 - acc: 0.007 - ETA: 2s - loss: 8.1739 - acc: 0.007 - ETA: 2s - loss: 8.1718 - acc: 0.007 - ETA: 2s - loss: 8.1696 - acc: 0.007 - ETA: 2s - loss: 8.1745 - acc: 0.007 - ETA: 2s - loss: 8.1566 - acc: 0.008 - ETA: 2s - loss: 8.1284 - acc: 0.008 - ETA: 2s - loss: 8.1337 - acc: 0.008 - ETA: 2s - loss: 8.1438 - acc: 0.008 - ETA: 2s - loss: 8.1611 - acc: 0.008 - ETA: 2s - loss: 8.1685 - acc: 0.008 - ETA: 2s - loss: 8.1793 - acc: 0.008 - ETA: 1s - loss: 8.1680 - acc: 0.008 - ETA: 1s - loss: 8.1902 - acc: 0.008 - ETA: 1s - loss: 8.1852 - acc: 0.008 - ETA: 1s - loss: 8.1841 - acc: 0.008 - ETA: 1s - loss: 8.1960 - acc: 0.008 - ETA: 1s - loss: 8.2018 - acc: 0.008 - ETA: 1s - loss: 8.2040 - acc: 0.008 - ETA: 1s - loss: 8.2120 - acc: 0.008 - ETA: 1s - loss: 8.1977 - acc: 0.008 - ETA: 1s - loss: 8.1814 - acc: 0.008 - ETA: 1s - loss: 8.1770 - acc: 0.008 - ETA: 1s - loss: 8.1768 - acc: 0.008 - ETA: 1s - loss: 8.1552 - acc: 0.008 - ETA: 1s - loss: 8.1502 - acc: 0.008 - ETA: 1s - loss: 8.1756 - acc: 0.008 - ETA: 1s - loss: 8.1756 - acc: 0.008 - ETA: 0s - loss: 8.1668 - acc: 0.008 - ETA: 0s - loss: 8.1674 - acc: 0.008 - ETA: 0s - loss: 8.1569 - acc: 0.008 - ETA: 0s - loss: 8.1722 - acc: 0.008 - ETA: 0s - loss: 8.1654 - acc: 0.008 - ETA: 0s - loss: 8.1551 - acc: 0.007 - ETA: 0s - loss: 8.1611 - acc: 0.007 - ETA: 0s - loss: 8.1557 - acc: 0.007 - ETA: 0s - loss: 8.1532 - acc: 0.007 - ETA: 0s - loss: 8.1607 - acc: 0.007 - ETA: 0s - loss: 8.1662 - acc: 0.008 - ETA: 0s - loss: 8.1521 - acc: 0.008 - ETA: 0s - loss: 8.1721 - acc: 0.008 - ETA: 0s - loss: 8.1781 - acc: 0.007 - ETA: 0s - loss: 8.1844 - acc: 0.007 - 8s 1ms/step - loss: 8.1801 - acc: 0.0079 - val_loss: 8.2412 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 8.10759\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 6.5477 - acc: 0.0000e+0 - ETA: 6s - loss: 8.8109 - acc: 0.0000e+0 - ETA: 6s - loss: 8.3848 - acc: 0.0000e+0 - ETA: 6s - loss: 7.9101 - acc: 0.0000e+0 - ETA: 6s - loss: 8.2732 - acc: 0.0038    - ETA: 6s - loss: 8.2303 - acc: 0.003 - ETA: 6s - loss: 8.1670 - acc: 0.005 - ETA: 6s - loss: 8.0520 - acc: 0.009 - ETA: 6s - loss: 8.1461 - acc: 0.010 - ETA: 6s - loss: 8.0461 - acc: 0.008 - ETA: 6s - loss: 8.0582 - acc: 0.008 - ETA: 6s - loss: 7.9808 - acc: 0.007 - ETA: 6s - loss: 7.8215 - acc: 0.008 - ETA: 6s - loss: 7.8316 - acc: 0.007 - ETA: 6s - loss: 7.9524 - acc: 0.007 - ETA: 6s - loss: 8.0862 - acc: 0.006 - ETA: 5s - loss: 8.0631 - acc: 0.006 - ETA: 5s - loss: 8.1393 - acc: 0.006 - ETA: 5s - loss: 8.1567 - acc: 0.006 - ETA: 5s - loss: 8.2375 - acc: 0.006 - ETA: 5s - loss: 8.2730 - acc: 0.005 - ETA: 5s - loss: 8.2848 - acc: 0.005 - ETA: 5s - loss: 8.2216 - acc: 0.005 - ETA: 5s - loss: 8.1969 - acc: 0.005 - ETA: 5s - loss: 8.1951 - acc: 0.005 - ETA: 5s - loss: 8.1965 - acc: 0.005 - ETA: 5s - loss: 8.1646 - acc: 0.005 - ETA: 5s - loss: 8.0978 - acc: 0.006 - ETA: 5s - loss: 8.0797 - acc: 0.006 - ETA: 5s - loss: 8.1298 - acc: 0.008 - ETA: 5s - loss: 8.1493 - acc: 0.008 - ETA: 5s - loss: 8.1038 - acc: 0.008 - ETA: 4s - loss: 8.1696 - acc: 0.007 - ETA: 4s - loss: 8.1808 - acc: 0.008 - ETA: 4s - loss: 8.1562 - acc: 0.008 - ETA: 4s - loss: 8.1868 - acc: 0.008 - ETA: 4s - loss: 8.1711 - acc: 0.008 - ETA: 4s - loss: 8.1857 - acc: 0.008 - ETA: 4s - loss: 8.1777 - acc: 0.008 - ETA: 4s - loss: 8.1510 - acc: 0.008 - ETA: 4s - loss: 8.1458 - acc: 0.008 - ETA: 4s - loss: 8.1675 - acc: 0.008 - ETA: 4s - loss: 8.1925 - acc: 0.008 - ETA: 4s - loss: 8.2048 - acc: 0.008 - ETA: 4s - loss: 8.2003 - acc: 0.008 - ETA: 4s - loss: 8.1699 - acc: 0.008 - ETA: 4s - loss: 8.2176 - acc: 0.008 - ETA: 4s - loss: 8.2233 - acc: 0.008 - ETA: 3s - loss: 8.2392 - acc: 0.007 - ETA: 3s - loss: 8.2284 - acc: 0.007 - ETA: 3s - loss: 8.2196 - acc: 0.007 - ETA: 3s - loss: 8.2023 - acc: 0.007 - ETA: 3s - loss: 8.2190 - acc: 0.007 - ETA: 3s - loss: 8.2338 - acc: 0.007 - ETA: 3s - loss: 8.2345 - acc: 0.007 - ETA: 3s - loss: 8.2265 - acc: 0.007 - ETA: 3s - loss: 8.2480 - acc: 0.008 - ETA: 3s - loss: 8.2467 - acc: 0.008 - ETA: 3s - loss: 8.2227 - acc: 0.008 - ETA: 3s - loss: 8.1999 - acc: 0.008 - ETA: 3s - loss: 8.2137 - acc: 0.008 - ETA: 3s - loss: 8.1847 - acc: 0.008 - ETA: 3s - loss: 8.1938 - acc: 0.008 - ETA: 3s - loss: 8.1736 - acc: 0.007 - ETA: 2s - loss: 8.1863 - acc: 0.007 - ETA: 2s - loss: 8.2109 - acc: 0.007 - ETA: 2s - loss: 8.2150 - acc: 0.007 - ETA: 2s - loss: 8.2132 - acc: 0.007 - ETA: 2s - loss: 8.2230 - acc: 0.007 - ETA: 2s - loss: 8.2259 - acc: 0.007 - ETA: 2s - loss: 8.2589 - acc: 0.007 - ETA: 2s - loss: 8.2463 - acc: 0.007 - ETA: 2s - loss: 8.2748 - acc: 0.007 - ETA: 2s - loss: 8.2692 - acc: 0.007 - ETA: 2s - loss: 8.2892 - acc: 0.007 - ETA: 2s - loss: 8.2963 - acc: 0.007 - ETA: 2s - loss: 8.2935 - acc: 0.007 - ETA: 2s - loss: 8.2912 - acc: 0.007 - ETA: 2s - loss: 8.2810 - acc: 0.007 - ETA: 2s - loss: 8.2804 - acc: 0.007 - ETA: 1s - loss: 8.2695 - acc: 0.007 - ETA: 1s - loss: 8.2748 - acc: 0.007 - ETA: 1s - loss: 8.2969 - acc: 0.006 - ETA: 1s - loss: 8.2886 - acc: 0.007 - ETA: 1s - loss: 8.3003 - acc: 0.006 - ETA: 1s - loss: 8.3057 - acc: 0.007 - ETA: 1s - loss: 8.3131 - acc: 0.007 - ETA: 1s - loss: 8.3221 - acc: 0.007 - ETA: 1s - loss: 8.3161 - acc: 0.007 - ETA: 1s - loss: 8.3277 - acc: 0.007 - ETA: 1s - loss: 8.3266 - acc: 0.007 - ETA: 1s - loss: 8.3400 - acc: 0.007 - ETA: 1s - loss: 8.3410 - acc: 0.007 - ETA: 1s - loss: 8.3357 - acc: 0.007 - ETA: 1s - loss: 8.3335 - acc: 0.006 - ETA: 1s - loss: 8.3186 - acc: 0.006 - ETA: 0s - loss: 8.3178 - acc: 0.006 - ETA: 0s - loss: 8.2975 - acc: 0.006 - ETA: 0s - loss: 8.2944 - acc: 0.006 - ETA: 0s - loss: 8.3039 - acc: 0.006 - ETA: 0s - loss: 8.3108 - acc: 0.007 - ETA: 0s - loss: 8.3057 - acc: 0.006 - ETA: 0s - loss: 8.3028 - acc: 0.006 - ETA: 0s - loss: 8.2970 - acc: 0.006 - ETA: 0s - loss: 8.3050 - acc: 0.006 - ETA: 0s - loss: 8.2965 - acc: 0.006 - ETA: 0s - loss: 8.3077 - acc: 0.006 - ETA: 0s - loss: 8.2948 - acc: 0.006 - ETA: 0s - loss: 8.2901 - acc: 0.006 - ETA: 0s - loss: 8.2900 - acc: 0.006 - ETA: 0s - loss: 8.2790 - acc: 0.006 - 8s 1ms/step - loss: 8.2824 - acc: 0.0066 - val_loss: 8.1469 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 8.10759\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 8.1413 - acc: 0.0000e+0 - ETA: 6s - loss: 8.9741 - acc: 0.0125    - ETA: 6s - loss: 8.6315 - acc: 0.007 - ETA: 6s - loss: 8.4088 - acc: 0.005 - ETA: 6s - loss: 8.2346 - acc: 0.007 - ETA: 6s - loss: 8.1071 - acc: 0.006 - ETA: 6s - loss: 8.3638 - acc: 0.005 - ETA: 6s - loss: 8.4028 - acc: 0.004 - ETA: 6s - loss: 8.3234 - acc: 0.004 - ETA: 6s - loss: 8.3172 - acc: 0.003 - ETA: 6s - loss: 8.4049 - acc: 0.003 - ETA: 6s - loss: 8.3705 - acc: 0.004 - ETA: 6s - loss: 8.4285 - acc: 0.004 - ETA: 6s - loss: 8.4497 - acc: 0.003 - ETA: 6s - loss: 8.4168 - acc: 0.003 - ETA: 6s - loss: 8.3700 - acc: 0.003 - ETA: 5s - loss: 8.3482 - acc: 0.003 - ETA: 5s - loss: 8.3682 - acc: 0.002 - ETA: 5s - loss: 8.3805 - acc: 0.002 - ETA: 5s - loss: 8.3704 - acc: 0.003 - ETA: 5s - loss: 8.3740 - acc: 0.003 - ETA: 5s - loss: 8.3288 - acc: 0.003 - ETA: 5s - loss: 8.3535 - acc: 0.003 - ETA: 5s - loss: 8.3458 - acc: 0.003 - ETA: 5s - loss: 8.3216 - acc: 0.003 - ETA: 5s - loss: 8.2487 - acc: 0.003 - ETA: 5s - loss: 8.2726 - acc: 0.003 - ETA: 5s - loss: 8.2648 - acc: 0.004 - ETA: 5s - loss: 8.1929 - acc: 0.004 - ETA: 5s - loss: 8.2276 - acc: 0.004 - ETA: 5s - loss: 8.1788 - acc: 0.004 - ETA: 5s - loss: 8.1938 - acc: 0.004 - ETA: 4s - loss: 8.1790 - acc: 0.005 - ETA: 4s - loss: 8.1806 - acc: 0.005 - ETA: 4s - loss: 8.2029 - acc: 0.004 - ETA: 4s - loss: 8.2240 - acc: 0.004 - ETA: 4s - loss: 8.2028 - acc: 0.004 - ETA: 4s - loss: 8.1906 - acc: 0.004 - ETA: 4s - loss: 8.2019 - acc: 0.004 - ETA: 4s - loss: 8.2422 - acc: 0.005 - ETA: 4s - loss: 8.2314 - acc: 0.005 - ETA: 4s - loss: 8.2484 - acc: 0.006 - ETA: 4s - loss: 8.2975 - acc: 0.005 - ETA: 4s - loss: 8.2903 - acc: 0.005 - ETA: 4s - loss: 8.2673 - acc: 0.006 - ETA: 4s - loss: 8.2779 - acc: 0.006 - ETA: 4s - loss: 8.2861 - acc: 0.006 - ETA: 4s - loss: 8.2716 - acc: 0.006 - ETA: 3s - loss: 8.2552 - acc: 0.006 - ETA: 3s - loss: 8.2760 - acc: 0.006 - ETA: 3s - loss: 8.2718 - acc: 0.006 - ETA: 3s - loss: 8.2740 - acc: 0.006 - ETA: 3s - loss: 8.2983 - acc: 0.006 - ETA: 3s - loss: 8.2843 - acc: 0.006 - ETA: 3s - loss: 8.2882 - acc: 0.006 - ETA: 3s - loss: 8.3061 - acc: 0.006 - ETA: 3s - loss: 8.2862 - acc: 0.006 - ETA: 3s - loss: 8.2856 - acc: 0.006 - ETA: 3s - loss: 8.2708 - acc: 0.006 - ETA: 3s - loss: 8.3048 - acc: 0.006 - ETA: 3s - loss: 8.2913 - acc: 0.006 - ETA: 3s - loss: 8.2882 - acc: 0.006 - ETA: 3s - loss: 8.3253 - acc: 0.006 - ETA: 3s - loss: 8.3223 - acc: 0.006 - ETA: 2s - loss: 8.3185 - acc: 0.006 - ETA: 2s - loss: 8.2992 - acc: 0.007 - ETA: 2s - loss: 8.3037 - acc: 0.007 - ETA: 2s - loss: 8.2604 - acc: 0.006 - ETA: 2s - loss: 8.2596 - acc: 0.006 - ETA: 2s - loss: 8.2494 - acc: 0.006 - ETA: 2s - loss: 8.2678 - acc: 0.006 - ETA: 2s - loss: 8.2603 - acc: 0.006 - ETA: 2s - loss: 8.2736 - acc: 0.006 - ETA: 2s - loss: 8.2728 - acc: 0.006 - ETA: 2s - loss: 8.2598 - acc: 0.006 - ETA: 2s - loss: 8.2567 - acc: 0.006 - ETA: 2s - loss: 8.2759 - acc: 0.006 - ETA: 2s - loss: 8.2854 - acc: 0.006 - ETA: 2s - loss: 8.2713 - acc: 0.006 - ETA: 2s - loss: 8.2857 - acc: 0.006 - ETA: 1s - loss: 8.2663 - acc: 0.006 - ETA: 1s - loss: 8.2683 - acc: 0.007 - ETA: 1s - loss: 8.2719 - acc: 0.006 - ETA: 1s - loss: 8.2638 - acc: 0.007 - ETA: 1s - loss: 8.2668 - acc: 0.007 - ETA: 1s - loss: 8.2632 - acc: 0.007 - ETA: 1s - loss: 8.2524 - acc: 0.006 - ETA: 1s - loss: 8.2396 - acc: 0.006 - ETA: 1s - loss: 8.2625 - acc: 0.006 - ETA: 1s - loss: 8.2318 - acc: 0.006 - ETA: 1s - loss: 8.2053 - acc: 0.006 - ETA: 1s - loss: 8.2030 - acc: 0.006 - ETA: 1s - loss: 8.2067 - acc: 0.006 - ETA: 1s - loss: 8.2120 - acc: 0.006 - ETA: 1s - loss: 8.2174 - acc: 0.006 - ETA: 1s - loss: 8.2114 - acc: 0.006 - ETA: 0s - loss: 8.1995 - acc: 0.006 - ETA: 0s - loss: 8.1791 - acc: 0.006 - ETA: 0s - loss: 8.1703 - acc: 0.006 - ETA: 0s - loss: 8.1803 - acc: 0.006 - ETA: 0s - loss: 8.1844 - acc: 0.006 - ETA: 0s - loss: 8.1829 - acc: 0.006 - ETA: 0s - loss: 8.1671 - acc: 0.006 - ETA: 0s - loss: 8.1649 - acc: 0.006 - ETA: 0s - loss: 8.1850 - acc: 0.006 - ETA: 0s - loss: 8.1785 - acc: 0.006 - ETA: 0s - loss: 8.1763 - acc: 0.006 - ETA: 0s - loss: 8.1706 - acc: 0.006 - ETA: 0s - loss: 8.1612 - acc: 0.006 - ETA: 0s - loss: 8.1786 - acc: 0.006 - ETA: 0s - loss: 8.1896 - acc: 0.006 - 7s 1ms/step - loss: 8.1935 - acc: 0.0066 - val_loss: 7.9929 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.10759 to 7.99290, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 8.9538 - acc: 0.0000e+0 - ETA: 6s - loss: 9.4489 - acc: 0.0000e+0 - ETA: 6s - loss: 9.3702 - acc: 0.0000e+0 - ETA: 6s - loss: 9.3970 - acc: 0.0000e+0 - ETA: 6s - loss: 9.5243 - acc: 0.0000e+0 - ETA: 6s - loss: 9.6293 - acc: 0.0031    - ETA: 6s - loss: 9.1842 - acc: 0.005 - ETA: 6s - loss: 8.9783 - acc: 0.004 - ETA: 6s - loss: 8.6563 - acc: 0.008 - ETA: 6s - loss: 8.5433 - acc: 0.010 - ETA: 6s - loss: 8.6535 - acc: 0.011 - ETA: 6s - loss: 8.5857 - acc: 0.011 - ETA: 6s - loss: 8.5482 - acc: 0.012 - ETA: 6s - loss: 8.5238 - acc: 0.011 - ETA: 6s - loss: 8.4644 - acc: 0.010 - ETA: 6s - loss: 8.4039 - acc: 0.010 - ETA: 6s - loss: 8.4722 - acc: 0.011 - ETA: 5s - loss: 8.4672 - acc: 0.011 - ETA: 5s - loss: 8.4538 - acc: 0.010 - ETA: 5s - loss: 8.4683 - acc: 0.010 - ETA: 5s - loss: 8.4399 - acc: 0.010 - ETA: 5s - loss: 8.4665 - acc: 0.010 - ETA: 5s - loss: 8.4750 - acc: 0.010 - ETA: 5s - loss: 8.4964 - acc: 0.010 - ETA: 5s - loss: 8.5480 - acc: 0.010 - ETA: 5s - loss: 8.5773 - acc: 0.010 - ETA: 5s - loss: 8.6274 - acc: 0.010 - ETA: 5s - loss: 8.5335 - acc: 0.010 - ETA: 5s - loss: 8.4743 - acc: 0.010 - ETA: 5s - loss: 8.4861 - acc: 0.010 - ETA: 5s - loss: 8.4707 - acc: 0.010 - ETA: 5s - loss: 8.4416 - acc: 0.010 - ETA: 4s - loss: 8.3812 - acc: 0.010 - ETA: 4s - loss: 8.3810 - acc: 0.010 - ETA: 4s - loss: 8.3220 - acc: 0.010 - ETA: 4s - loss: 8.3253 - acc: 0.010 - ETA: 4s - loss: 8.2789 - acc: 0.010 - ETA: 4s - loss: 8.3100 - acc: 0.009 - ETA: 4s - loss: 8.3146 - acc: 0.009 - ETA: 4s - loss: 8.3363 - acc: 0.009 - ETA: 4s - loss: 8.3224 - acc: 0.009 - ETA: 4s - loss: 8.3438 - acc: 0.009 - ETA: 4s - loss: 8.3315 - acc: 0.009 - ETA: 4s - loss: 8.3455 - acc: 0.008 - ETA: 4s - loss: 8.3541 - acc: 0.008 - ETA: 4s - loss: 8.3669 - acc: 0.008 - ETA: 4s - loss: 8.3796 - acc: 0.008 - ETA: 4s - loss: 8.3900 - acc: 0.008 - ETA: 3s - loss: 8.4028 - acc: 0.008 - ETA: 3s - loss: 8.3870 - acc: 0.008 - ETA: 3s - loss: 8.3956 - acc: 0.008 - ETA: 3s - loss: 8.3846 - acc: 0.008 - ETA: 3s - loss: 8.4155 - acc: 0.008 - ETA: 3s - loss: 8.4216 - acc: 0.008 - ETA: 3s - loss: 8.4025 - acc: 0.008 - ETA: 3s - loss: 8.4070 - acc: 0.008 - ETA: 3s - loss: 8.4008 - acc: 0.008 - ETA: 3s - loss: 8.3684 - acc: 0.008 - ETA: 3s - loss: 8.3737 - acc: 0.008 - ETA: 3s - loss: 8.3767 - acc: 0.008 - ETA: 3s - loss: 8.3895 - acc: 0.008 - ETA: 3s - loss: 8.4039 - acc: 0.008 - ETA: 3s - loss: 8.4174 - acc: 0.009 - ETA: 3s - loss: 8.4009 - acc: 0.008 - ETA: 2s - loss: 8.3902 - acc: 0.009 - ETA: 2s - loss: 8.3550 - acc: 0.009 - ETA: 2s - loss: 8.3521 - acc: 0.009 - ETA: 2s - loss: 8.3551 - acc: 0.009 - ETA: 2s - loss: 8.3418 - acc: 0.009 - ETA: 2s - loss: 8.3235 - acc: 0.009 - ETA: 2s - loss: 8.3350 - acc: 0.009 - ETA: 2s - loss: 8.3237 - acc: 0.009 - ETA: 2s - loss: 8.3284 - acc: 0.009 - ETA: 2s - loss: 8.3287 - acc: 0.009 - ETA: 2s - loss: 8.3070 - acc: 0.009 - ETA: 2s - loss: 8.2737 - acc: 0.009 - ETA: 2s - loss: 8.2639 - acc: 0.009 - ETA: 2s - loss: 8.2401 - acc: 0.008 - ETA: 2s - loss: 8.2235 - acc: 0.008 - ETA: 2s - loss: 8.2197 - acc: 0.008 - ETA: 1s - loss: 8.2093 - acc: 0.008 - ETA: 1s - loss: 8.2050 - acc: 0.008 - ETA: 1s - loss: 8.2135 - acc: 0.008 - ETA: 1s - loss: 8.2345 - acc: 0.008 - ETA: 1s - loss: 8.2212 - acc: 0.008 - ETA: 1s - loss: 8.2220 - acc: 0.008 - ETA: 1s - loss: 8.2582 - acc: 0.008 - ETA: 1s - loss: 8.2503 - acc: 0.009 - ETA: 1s - loss: 8.2356 - acc: 0.009 - ETA: 1s - loss: 8.2236 - acc: 0.009 - ETA: 1s - loss: 8.2287 - acc: 0.008 - ETA: 1s - loss: 8.2159 - acc: 0.008 - ETA: 1s - loss: 8.2229 - acc: 0.008 - ETA: 1s - loss: 8.2317 - acc: 0.008 - ETA: 1s - loss: 8.2476 - acc: 0.008 - ETA: 1s - loss: 8.2410 - acc: 0.008 - ETA: 0s - loss: 8.2433 - acc: 0.008 - ETA: 0s - loss: 8.2374 - acc: 0.008 - ETA: 0s - loss: 8.2330 - acc: 0.009 - ETA: 0s - loss: 8.2037 - acc: 0.008 - ETA: 0s - loss: 8.2001 - acc: 0.009 - ETA: 0s - loss: 8.1920 - acc: 0.008 - ETA: 0s - loss: 8.1819 - acc: 0.009 - ETA: 0s - loss: 8.1920 - acc: 0.008 - ETA: 0s - loss: 8.1792 - acc: 0.008 - ETA: 0s - loss: 8.1647 - acc: 0.008 - ETA: 0s - loss: 8.1757 - acc: 0.008 - ETA: 0s - loss: 8.1722 - acc: 0.008 - ETA: 0s - loss: 8.1718 - acc: 0.008 - ETA: 0s - loss: 8.1712 - acc: 0.008 - ETA: 0s - loss: 8.1721 - acc: 0.008 - 8s 1ms/step - loss: 8.1842 - acc: 0.0085 - val_loss: 7.8950 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.99290 to 7.89497, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 5.6413 - acc: 0.0000e+0 - ETA: 7s - loss: 8.8735 - acc: 0.0125    - ETA: 6s - loss: 7.7776 - acc: 0.014 - ETA: 6s - loss: 8.5538 - acc: 0.010 - ETA: 6s - loss: 8.4671 - acc: 0.007 - ETA: 6s - loss: 8.6594 - acc: 0.006 - ETA: 6s - loss: 8.4906 - acc: 0.005 - ETA: 6s - loss: 8.2993 - acc: 0.004 - ETA: 6s - loss: 8.4378 - acc: 0.006 - ETA: 6s - loss: 8.5452 - acc: 0.008 - ETA: 6s - loss: 8.5711 - acc: 0.009 - ETA: 6s - loss: 8.5373 - acc: 0.008 - ETA: 6s - loss: 8.5734 - acc: 0.008 - ETA: 6s - loss: 8.4902 - acc: 0.007 - ETA: 6s - loss: 8.6330 - acc: 0.008 - ETA: 6s - loss: 8.5295 - acc: 0.008 - ETA: 6s - loss: 8.4913 - acc: 0.009 - ETA: 5s - loss: 8.4534 - acc: 0.008 - ETA: 5s - loss: 8.3646 - acc: 0.008 - ETA: 5s - loss: 8.3935 - acc: 0.008 - ETA: 5s - loss: 8.2865 - acc: 0.008 - ETA: 5s - loss: 8.2853 - acc: 0.008 - ETA: 5s - loss: 8.2976 - acc: 0.009 - ETA: 5s - loss: 8.2793 - acc: 0.008 - ETA: 5s - loss: 8.3276 - acc: 0.008 - ETA: 5s - loss: 8.3594 - acc: 0.008 - ETA: 5s - loss: 8.4204 - acc: 0.008 - ETA: 5s - loss: 8.3902 - acc: 0.008 - ETA: 5s - loss: 8.3903 - acc: 0.008 - ETA: 5s - loss: 8.4123 - acc: 0.008 - ETA: 5s - loss: 8.4166 - acc: 0.008 - ETA: 5s - loss: 8.4427 - acc: 0.008 - ETA: 4s - loss: 8.4357 - acc: 0.008 - ETA: 4s - loss: 8.3953 - acc: 0.008 - ETA: 4s - loss: 8.4094 - acc: 0.009 - ETA: 4s - loss: 8.4082 - acc: 0.009 - ETA: 4s - loss: 8.3944 - acc: 0.009 - ETA: 4s - loss: 8.3802 - acc: 0.009 - ETA: 4s - loss: 8.3703 - acc: 0.009 - ETA: 4s - loss: 8.4131 - acc: 0.009 - ETA: 4s - loss: 8.4383 - acc: 0.009 - ETA: 4s - loss: 8.3991 - acc: 0.010 - ETA: 4s - loss: 8.3454 - acc: 0.009 - ETA: 4s - loss: 8.3564 - acc: 0.009 - ETA: 4s - loss: 8.3574 - acc: 0.009 - ETA: 4s - loss: 8.3133 - acc: 0.009 - ETA: 4s - loss: 8.3337 - acc: 0.009 - ETA: 4s - loss: 8.3480 - acc: 0.009 - ETA: 3s - loss: 8.3381 - acc: 0.009 - ETA: 3s - loss: 8.3324 - acc: 0.009 - ETA: 3s - loss: 8.3342 - acc: 0.009 - ETA: 3s - loss: 8.3207 - acc: 0.009 - ETA: 3s - loss: 8.3078 - acc: 0.009 - ETA: 3s - loss: 8.2898 - acc: 0.009 - ETA: 3s - loss: 8.2964 - acc: 0.008 - ETA: 3s - loss: 8.2924 - acc: 0.009 - ETA: 3s - loss: 8.2936 - acc: 0.009 - ETA: 3s - loss: 8.3086 - acc: 0.009 - ETA: 3s - loss: 8.2973 - acc: 0.009 - ETA: 3s - loss: 8.3132 - acc: 0.009 - ETA: 3s - loss: 8.3142 - acc: 0.009 - ETA: 3s - loss: 8.3188 - acc: 0.009 - ETA: 3s - loss: 8.2857 - acc: 0.009 - ETA: 3s - loss: 8.2608 - acc: 0.009 - ETA: 2s - loss: 8.2563 - acc: 0.009 - ETA: 2s - loss: 8.2420 - acc: 0.009 - ETA: 2s - loss: 8.2279 - acc: 0.009 - ETA: 2s - loss: 8.2203 - acc: 0.008 - ETA: 2s - loss: 8.2547 - acc: 0.008 - ETA: 2s - loss: 8.2416 - acc: 0.008 - ETA: 2s - loss: 8.2551 - acc: 0.009 - ETA: 2s - loss: 8.2337 - acc: 0.009 - ETA: 2s - loss: 8.2509 - acc: 0.009 - ETA: 2s - loss: 8.2472 - acc: 0.009 - ETA: 2s - loss: 8.2168 - acc: 0.009 - ETA: 2s - loss: 8.2118 - acc: 0.009 - ETA: 2s - loss: 8.2240 - acc: 0.009 - ETA: 2s - loss: 8.2193 - acc: 0.009 - ETA: 2s - loss: 8.2046 - acc: 0.009 - ETA: 2s - loss: 8.1977 - acc: 0.009 - ETA: 1s - loss: 8.2083 - acc: 0.009 - ETA: 1s - loss: 8.2177 - acc: 0.009 - ETA: 1s - loss: 8.2096 - acc: 0.008 - ETA: 1s - loss: 8.2353 - acc: 0.009 - ETA: 1s - loss: 8.2332 - acc: 0.008 - ETA: 1s - loss: 8.2289 - acc: 0.009 - ETA: 1s - loss: 8.2205 - acc: 0.008 - ETA: 1s - loss: 8.2195 - acc: 0.009 - ETA: 1s - loss: 8.2241 - acc: 0.008 - ETA: 1s - loss: 8.2237 - acc: 0.009 - ETA: 1s - loss: 8.2045 - acc: 0.009 - ETA: 1s - loss: 8.2094 - acc: 0.009 - ETA: 1s - loss: 8.2074 - acc: 0.009 - ETA: 1s - loss: 8.2120 - acc: 0.009 - ETA: 1s - loss: 8.2091 - acc: 0.009 - ETA: 1s - loss: 8.2119 - acc: 0.009 - ETA: 0s - loss: 8.2105 - acc: 0.009 - ETA: 0s - loss: 8.2265 - acc: 0.009 - ETA: 0s - loss: 8.2148 - acc: 0.009 - ETA: 0s - loss: 8.2058 - acc: 0.009 - ETA: 0s - loss: 8.2011 - acc: 0.009 - ETA: 0s - loss: 8.1844 - acc: 0.009 - ETA: 0s - loss: 8.1875 - acc: 0.009 - ETA: 0s - loss: 8.1735 - acc: 0.009 - ETA: 0s - loss: 8.1905 - acc: 0.009 - ETA: 0s - loss: 8.1949 - acc: 0.009 - ETA: 0s - loss: 8.2093 - acc: 0.009 - ETA: 0s - loss: 8.2197 - acc: 0.009 - ETA: 0s - loss: 8.2259 - acc: 0.009 - ETA: 0s - loss: 8.2028 - acc: 0.009 - ETA: 0s - loss: 8.2223 - acc: 0.009 - 8s 1ms/step - loss: 8.2151 - acc: 0.0096 - val_loss: 8.2032 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.89497\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 9.1373 - acc: 0.0000e+0 - ETA: 6s - loss: 7.9766 - acc: 0.0125    - ETA: 6s - loss: 7.7422 - acc: 0.014 - ETA: 6s - loss: 7.8658 - acc: 0.015 - ETA: 6s - loss: 7.9962 - acc: 0.011 - ETA: 6s - loss: 8.1834 - acc: 0.009 - ETA: 6s - loss: 8.2370 - acc: 0.007 - ETA: 6s - loss: 8.1803 - acc: 0.009 - ETA: 6s - loss: 8.2229 - acc: 0.010 - ETA: 6s - loss: 8.3912 - acc: 0.010 - ETA: 6s - loss: 8.4674 - acc: 0.011 - ETA: 6s - loss: 8.6696 - acc: 0.010 - ETA: 6s - loss: 8.5541 - acc: 0.010 - ETA: 6s - loss: 8.5905 - acc: 0.011 - ETA: 6s - loss: 8.5987 - acc: 0.011 - ETA: 5s - loss: 8.5341 - acc: 0.010 - ETA: 5s - loss: 8.4442 - acc: 0.011 - ETA: 5s - loss: 8.4261 - acc: 0.010 - ETA: 5s - loss: 8.4090 - acc: 0.010 - ETA: 5s - loss: 8.4226 - acc: 0.010 - ETA: 5s - loss: 8.3519 - acc: 0.009 - ETA: 5s - loss: 8.3137 - acc: 0.009 - ETA: 5s - loss: 8.3151 - acc: 0.009 - ETA: 5s - loss: 8.3293 - acc: 0.008 - ETA: 5s - loss: 8.3196 - acc: 0.008 - ETA: 5s - loss: 8.3429 - acc: 0.009 - ETA: 5s - loss: 8.3633 - acc: 0.009 - ETA: 5s - loss: 8.3591 - acc: 0.009 - ETA: 5s - loss: 8.3701 - acc: 0.008 - ETA: 5s - loss: 8.3895 - acc: 0.008 - ETA: 5s - loss: 8.3993 - acc: 0.008 - ETA: 5s - loss: 8.3907 - acc: 0.009 - ETA: 4s - loss: 8.3947 - acc: 0.009 - ETA: 4s - loss: 8.3421 - acc: 0.009 - ETA: 4s - loss: 8.3233 - acc: 0.009 - ETA: 4s - loss: 8.2977 - acc: 0.009 - ETA: 4s - loss: 8.2509 - acc: 0.008 - ETA: 4s - loss: 8.2355 - acc: 0.008 - ETA: 4s - loss: 8.2169 - acc: 0.008 - ETA: 4s - loss: 8.1924 - acc: 0.008 - ETA: 4s - loss: 8.1991 - acc: 0.007 - ETA: 4s - loss: 8.1776 - acc: 0.007 - ETA: 4s - loss: 8.1703 - acc: 0.007 - ETA: 4s - loss: 8.2218 - acc: 0.007 - ETA: 4s - loss: 8.1965 - acc: 0.007 - ETA: 4s - loss: 8.2069 - acc: 0.007 - ETA: 4s - loss: 8.2253 - acc: 0.007 - ETA: 4s - loss: 8.2278 - acc: 0.008 - ETA: 3s - loss: 8.2250 - acc: 0.007 - ETA: 3s - loss: 8.2304 - acc: 0.007 - ETA: 3s - loss: 8.2258 - acc: 0.007 - ETA: 3s - loss: 8.2251 - acc: 0.007 - ETA: 3s - loss: 8.2029 - acc: 0.007 - ETA: 3s - loss: 8.2087 - acc: 0.007 - ETA: 3s - loss: 8.1933 - acc: 0.007 - ETA: 3s - loss: 8.2106 - acc: 0.008 - ETA: 3s - loss: 8.2376 - acc: 0.008 - ETA: 3s - loss: 8.2447 - acc: 0.008 - ETA: 3s - loss: 8.2415 - acc: 0.008 - ETA: 3s - loss: 8.2221 - acc: 0.008 - ETA: 3s - loss: 8.2191 - acc: 0.008 - ETA: 3s - loss: 8.2197 - acc: 0.007 - ETA: 3s - loss: 8.2310 - acc: 0.007 - ETA: 3s - loss: 8.2032 - acc: 0.007 - ETA: 2s - loss: 8.1897 - acc: 0.008 - ETA: 2s - loss: 8.1813 - acc: 0.007 - ETA: 2s - loss: 8.1854 - acc: 0.007 - ETA: 2s - loss: 8.1765 - acc: 0.007 - ETA: 2s - loss: 8.1523 - acc: 0.007 - ETA: 2s - loss: 8.1532 - acc: 0.007 - ETA: 2s - loss: 8.1671 - acc: 0.007 - ETA: 2s - loss: 8.1584 - acc: 0.007 - ETA: 2s - loss: 8.1571 - acc: 0.007 - ETA: 2s - loss: 8.1705 - acc: 0.007 - ETA: 2s - loss: 8.1698 - acc: 0.007 - ETA: 2s - loss: 8.1704 - acc: 0.007 - ETA: 2s - loss: 8.1807 - acc: 0.007 - ETA: 2s - loss: 8.1652 - acc: 0.007 - ETA: 2s - loss: 8.1572 - acc: 0.007 - ETA: 2s - loss: 8.1911 - acc: 0.007 - ETA: 1s - loss: 8.1922 - acc: 0.007 - ETA: 1s - loss: 8.1892 - acc: 0.007 - ETA: 1s - loss: 8.2112 - acc: 0.007 - ETA: 1s - loss: 8.1912 - acc: 0.007 - ETA: 1s - loss: 8.1692 - acc: 0.007 - ETA: 1s - loss: 8.1686 - acc: 0.007 - ETA: 1s - loss: 8.1781 - acc: 0.007 - ETA: 1s - loss: 8.1971 - acc: 0.007 - ETA: 1s - loss: 8.1961 - acc: 0.007 - ETA: 1s - loss: 8.1947 - acc: 0.007 - ETA: 1s - loss: 8.2052 - acc: 0.007 - ETA: 1s - loss: 8.2041 - acc: 0.007 - ETA: 1s - loss: 8.2002 - acc: 0.007 - ETA: 1s - loss: 8.1930 - acc: 0.007 - ETA: 1s - loss: 8.1982 - acc: 0.008 - ETA: 1s - loss: 8.2012 - acc: 0.007 - ETA: 0s - loss: 8.1921 - acc: 0.007 - ETA: 0s - loss: 8.1945 - acc: 0.007 - ETA: 0s - loss: 8.2124 - acc: 0.007 - ETA: 0s - loss: 8.2060 - acc: 0.007 - ETA: 0s - loss: 8.2052 - acc: 0.007 - ETA: 0s - loss: 8.2014 - acc: 0.007 - ETA: 0s - loss: 8.2059 - acc: 0.007 - ETA: 0s - loss: 8.2055 - acc: 0.007 - ETA: 0s - loss: 8.2120 - acc: 0.007 - ETA: 0s - loss: 8.2102 - acc: 0.007 - ETA: 0s - loss: 8.2231 - acc: 0.007 - ETA: 0s - loss: 8.2128 - acc: 0.007 - ETA: 0s - loss: 8.2198 - acc: 0.007 - ETA: 0s - loss: 8.2189 - acc: 0.007 - ETA: 0s - loss: 8.2155 - acc: 0.007 - 8s 1ms/step - loss: 8.2294 - acc: 0.0076 - val_loss: 7.9510 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.89497\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 6s - loss: 8.9444 - acc: 0.050 - ETA: 6s - loss: 8.2471 - acc: 0.025 - ETA: 6s - loss: 8.0731 - acc: 0.014 - ETA: 6s - loss: 8.0093 - acc: 0.010 - ETA: 6s - loss: 8.0398 - acc: 0.007 - ETA: 6s - loss: 7.9135 - acc: 0.006 - ETA: 6s - loss: 7.9863 - acc: 0.007 - ETA: 6s - loss: 8.1074 - acc: 0.009 - ETA: 6s - loss: 8.1310 - acc: 0.008 - ETA: 6s - loss: 7.9878 - acc: 0.007 - ETA: 6s - loss: 8.1059 - acc: 0.008 - ETA: 6s - loss: 8.0222 - acc: 0.007 - ETA: 6s - loss: 8.0058 - acc: 0.008 - ETA: 6s - loss: 7.9695 - acc: 0.007 - ETA: 6s - loss: 7.9610 - acc: 0.007 - ETA: 6s - loss: 7.9800 - acc: 0.006 - ETA: 5s - loss: 8.0599 - acc: 0.006 - ETA: 5s - loss: 8.1543 - acc: 0.005 - ETA: 5s - loss: 8.1755 - acc: 0.005 - ETA: 5s - loss: 8.2468 - acc: 0.006 - ETA: 5s - loss: 8.2575 - acc: 0.006 - ETA: 5s - loss: 8.3189 - acc: 0.006 - ETA: 5s - loss: 8.2821 - acc: 0.006 - ETA: 5s - loss: 8.4027 - acc: 0.006 - ETA: 5s - loss: 8.4344 - acc: 0.006 - ETA: 5s - loss: 8.4106 - acc: 0.005 - ETA: 5s - loss: 8.4300 - acc: 0.005 - ETA: 5s - loss: 8.4681 - acc: 0.005 - ETA: 5s - loss: 8.3882 - acc: 0.005 - ETA: 5s - loss: 8.3514 - acc: 0.005 - ETA: 5s - loss: 8.3776 - acc: 0.005 - ETA: 5s - loss: 8.3780 - acc: 0.005 - ETA: 4s - loss: 8.3010 - acc: 0.006 - ETA: 4s - loss: 8.3119 - acc: 0.006 - ETA: 4s - loss: 8.3170 - acc: 0.006 - ETA: 4s - loss: 8.3026 - acc: 0.007 - ETA: 4s - loss: 8.2629 - acc: 0.006 - ETA: 4s - loss: 8.2309 - acc: 0.006 - ETA: 4s - loss: 8.2131 - acc: 0.006 - ETA: 4s - loss: 8.1904 - acc: 0.006 - ETA: 4s - loss: 8.2301 - acc: 0.006 - ETA: 4s - loss: 8.2488 - acc: 0.006 - ETA: 4s - loss: 8.2591 - acc: 0.006 - ETA: 4s - loss: 8.2816 - acc: 0.006 - ETA: 4s - loss: 8.2503 - acc: 0.006 - ETA: 4s - loss: 8.2883 - acc: 0.006 - ETA: 4s - loss: 8.2896 - acc: 0.006 - ETA: 4s - loss: 8.3028 - acc: 0.006 - ETA: 3s - loss: 8.3090 - acc: 0.006 - ETA: 3s - loss: 8.2897 - acc: 0.006 - ETA: 3s - loss: 8.3334 - acc: 0.006 - ETA: 3s - loss: 8.3255 - acc: 0.006 - ETA: 3s - loss: 8.3120 - acc: 0.006 - ETA: 3s - loss: 8.2997 - acc: 0.006 - ETA: 3s - loss: 8.3162 - acc: 0.006 - ETA: 3s - loss: 8.3233 - acc: 0.006 - ETA: 3s - loss: 8.3204 - acc: 0.006 - ETA: 3s - loss: 8.3418 - acc: 0.006 - ETA: 3s - loss: 8.3417 - acc: 0.006 - ETA: 3s - loss: 8.3369 - acc: 0.006 - ETA: 3s - loss: 8.3590 - acc: 0.006 - ETA: 3s - loss: 8.3429 - acc: 0.006 - ETA: 3s - loss: 8.3433 - acc: 0.006 - ETA: 3s - loss: 8.3479 - acc: 0.006 - ETA: 2s - loss: 8.3466 - acc: 0.006 - ETA: 2s - loss: 8.3429 - acc: 0.006 - ETA: 2s - loss: 8.3164 - acc: 0.006 - ETA: 2s - loss: 8.3046 - acc: 0.006 - ETA: 2s - loss: 8.3035 - acc: 0.006 - ETA: 2s - loss: 8.3225 - acc: 0.006 - ETA: 2s - loss: 8.3224 - acc: 0.006 - ETA: 2s - loss: 8.3095 - acc: 0.006 - ETA: 2s - loss: 8.2850 - acc: 0.006 - ETA: 2s - loss: 8.2929 - acc: 0.006 - ETA: 2s - loss: 8.2836 - acc: 0.006 - ETA: 2s - loss: 8.2702 - acc: 0.006 - ETA: 2s - loss: 8.2749 - acc: 0.006 - ETA: 2s - loss: 8.2846 - acc: 0.006 - ETA: 2s - loss: 8.2731 - acc: 0.006 - ETA: 2s - loss: 8.2754 - acc: 0.006 - ETA: 1s - loss: 8.2731 - acc: 0.006 - ETA: 1s - loss: 8.2835 - acc: 0.006 - ETA: 1s - loss: 8.2927 - acc: 0.006 - ETA: 1s - loss: 8.3031 - acc: 0.006 - ETA: 1s - loss: 8.2970 - acc: 0.006 - ETA: 1s - loss: 8.2914 - acc: 0.006 - ETA: 1s - loss: 8.3138 - acc: 0.006 - ETA: 1s - loss: 8.3153 - acc: 0.006 - ETA: 1s - loss: 8.3094 - acc: 0.006 - ETA: 1s - loss: 8.3066 - acc: 0.006 - ETA: 1s - loss: 8.3266 - acc: 0.006 - ETA: 1s - loss: 8.2980 - acc: 0.006 - ETA: 1s - loss: 8.2946 - acc: 0.006 - ETA: 1s - loss: 8.2905 - acc: 0.006 - ETA: 1s - loss: 8.2788 - acc: 0.006 - ETA: 1s - loss: 8.2757 - acc: 0.006 - ETA: 0s - loss: 8.2722 - acc: 0.006 - ETA: 0s - loss: 8.2791 - acc: 0.006 - ETA: 0s - loss: 8.2693 - acc: 0.006 - ETA: 0s - loss: 8.2714 - acc: 0.006 - ETA: 0s - loss: 8.2707 - acc: 0.006 - ETA: 0s - loss: 8.2964 - acc: 0.006 - ETA: 0s - loss: 8.2692 - acc: 0.006 - ETA: 0s - loss: 8.2817 - acc: 0.006 - ETA: 0s - loss: 8.2931 - acc: 0.006 - ETA: 0s - loss: 8.2922 - acc: 0.006 - ETA: 0s - loss: 8.2876 - acc: 0.006 - ETA: 0s - loss: 8.2880 - acc: 0.006 - ETA: 0s - loss: 8.2836 - acc: 0.006 - ETA: 0s - loss: 8.2775 - acc: 0.006 - ETA: 0s - loss: 8.2712 - acc: 0.006 - 7s 1ms/step - loss: 8.2768 - acc: 0.0061 - val_loss: 8.2231 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.89497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit_generator(train_generator, \\n          validation_data=validation_generator,validation_steps=1000,\\n          steps_per_epoch=3000, epochs=epochs, callbacks=[checkpointer], verbose=1)\\n          '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: 设置训练模型的epochs的数量\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "### 不要修改下方代码\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "'''\n",
    "model.fit_generator(train_generator, \n",
    "          validation_data=validation_generator,validation_steps=1000,\n",
    "          steps_per_epoch=3000, epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
    "          '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载具有最好验证loss的模型\n",
    "\n",
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型\n",
    "\n",
    "在狗图像的测试数据集上试用你的模型。确保测试准确率大于1%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8373%\n"
     ]
    }
   ],
   "source": [
    "# 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## 步骤 4: 使用一个CNN来区分狗的品种\n",
    "\n",
    "\n",
    "使用 迁移学习（Transfer Learning）的方法，能帮助我们在不损失准确率的情况下大大减少训练时间。在以下步骤中，你可以尝试使用迁移学习来训练你自己的CNN。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到从图像中提取的特征向量（Bottleneck Features）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型架构\n",
    "\n",
    "该模型使用预训练的 VGG-16 模型作为固定的图像特征提取器，其中 VGG-16 最后一层卷积层的输出被直接输入到我们的模型。我们只需要添加一个全局平均池化层以及一个全连接层，其中全连接层使用 softmax 激活函数，对每一个狗的种类都包含一个节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 编译模型\n",
    "\n",
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "6680/6680 [==============================] - ETA: 3:27 - loss: 14.8581 - acc: 0.0000e+ - ETA: 18s - loss: 14.7946 - acc: 0.0167     - ETA: 9s - loss: 14.2328 - acc: 0.037 - ETA: 6s - loss: 13.9161 - acc: 0.04 - ETA: 5s - loss: 13.8531 - acc: 0.04 - ETA: 4s - loss: 13.8593 - acc: 0.04 - ETA: 3s - loss: 13.7505 - acc: 0.04 - ETA: 3s - loss: 13.5403 - acc: 0.05 - ETA: 2s - loss: 13.5192 - acc: 0.05 - ETA: 2s - loss: 13.3916 - acc: 0.05 - ETA: 2s - loss: 13.3249 - acc: 0.05 - ETA: 1s - loss: 13.1944 - acc: 0.06 - ETA: 1s - loss: 13.0854 - acc: 0.06 - ETA: 1s - loss: 12.9721 - acc: 0.06 - ETA: 1s - loss: 12.8660 - acc: 0.07 - ETA: 1s - loss: 12.7541 - acc: 0.07 - ETA: 1s - loss: 12.6901 - acc: 0.08 - ETA: 0s - loss: 12.6186 - acc: 0.08 - ETA: 0s - loss: 12.5656 - acc: 0.08 - ETA: 0s - loss: 12.5058 - acc: 0.09 - ETA: 0s - loss: 12.4669 - acc: 0.09 - ETA: 0s - loss: 12.4114 - acc: 0.09 - ETA: 0s - loss: 12.3319 - acc: 0.10 - ETA: 0s - loss: 12.2511 - acc: 0.10 - ETA: 0s - loss: 12.1916 - acc: 0.10 - ETA: 0s - loss: 12.1238 - acc: 0.11 - ETA: 0s - loss: 12.0791 - acc: 0.11 - ETA: 0s - loss: 11.9984 - acc: 0.11 - ETA: 0s - loss: 11.9493 - acc: 0.12 - 2s 344us/step - loss: 11.9339 - acc: 0.1216 - val_loss: 10.1261 - val_acc: 0.2204\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.12608, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 2/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.3628 - acc: 0.300 - ETA: 1s - loss: 9.5437 - acc: 0.254 - ETA: 1s - loss: 9.5785 - acc: 0.268 - ETA: 1s - loss: 9.7218 - acc: 0.258 - ETA: 1s - loss: 9.7856 - acc: 0.258 - ETA: 1s - loss: 9.6555 - acc: 0.266 - ETA: 1s - loss: 9.6171 - acc: 0.269 - ETA: 1s - loss: 9.5206 - acc: 0.276 - ETA: 1s - loss: 9.4840 - acc: 0.276 - ETA: 1s - loss: 9.3842 - acc: 0.281 - ETA: 0s - loss: 9.3248 - acc: 0.285 - ETA: 0s - loss: 9.3649 - acc: 0.284 - ETA: 0s - loss: 9.3731 - acc: 0.286 - ETA: 0s - loss: 9.4188 - acc: 0.285 - ETA: 0s - loss: 9.3946 - acc: 0.288 - ETA: 0s - loss: 9.4254 - acc: 0.290 - ETA: 0s - loss: 9.4016 - acc: 0.293 - ETA: 0s - loss: 9.4139 - acc: 0.295 - ETA: 0s - loss: 9.3858 - acc: 0.298 - ETA: 0s - loss: 9.3370 - acc: 0.300 - ETA: 0s - loss: 9.3798 - acc: 0.299 - ETA: 0s - loss: 9.3854 - acc: 0.300 - ETA: 0s - loss: 9.4158 - acc: 0.300 - ETA: 0s - loss: 9.4411 - acc: 0.299 - ETA: 0s - loss: 9.4724 - acc: 0.298 - ETA: 0s - loss: 9.4603 - acc: 0.299 - ETA: 0s - loss: 9.4687 - acc: 0.300 - ETA: 0s - loss: 9.4688 - acc: 0.300 - ETA: 0s - loss: 9.4623 - acc: 0.301 - ETA: 0s - loss: 9.4493 - acc: 0.302 - 2s 244us/step - loss: 9.4453 - acc: 0.3031 - val_loss: 9.4992 - val_acc: 0.3054\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.12608 to 9.49922, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 3/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.7228 - acc: 0.400 - ETA: 1s - loss: 9.0267 - acc: 0.381 - ETA: 1s - loss: 8.8680 - acc: 0.370 - ETA: 1s - loss: 8.9280 - acc: 0.364 - ETA: 1s - loss: 8.8901 - acc: 0.364 - ETA: 1s - loss: 9.0266 - acc: 0.354 - ETA: 1s - loss: 9.1841 - acc: 0.343 - ETA: 1s - loss: 9.0403 - acc: 0.348 - ETA: 1s - loss: 8.9915 - acc: 0.352 - ETA: 1s - loss: 8.9834 - acc: 0.355 - ETA: 1s - loss: 9.0770 - acc: 0.353 - ETA: 0s - loss: 9.0050 - acc: 0.361 - ETA: 0s - loss: 9.0350 - acc: 0.360 - ETA: 0s - loss: 8.9765 - acc: 0.364 - ETA: 0s - loss: 8.9801 - acc: 0.363 - ETA: 0s - loss: 9.0007 - acc: 0.362 - ETA: 0s - loss: 9.0161 - acc: 0.359 - ETA: 0s - loss: 9.0509 - acc: 0.357 - ETA: 0s - loss: 9.0498 - acc: 0.358 - ETA: 0s - loss: 9.0344 - acc: 0.359 - ETA: 0s - loss: 8.9972 - acc: 0.361 - ETA: 0s - loss: 8.9993 - acc: 0.363 - ETA: 0s - loss: 8.9407 - acc: 0.366 - ETA: 0s - loss: 8.9300 - acc: 0.367 - ETA: 0s - loss: 8.9356 - acc: 0.366 - ETA: 0s - loss: 8.8957 - acc: 0.368 - ETA: 0s - loss: 8.8821 - acc: 0.369 - ETA: 0s - loss: 8.8845 - acc: 0.369 - ETA: 0s - loss: 8.9138 - acc: 0.368 - 2s 242us/step - loss: 8.8963 - acc: 0.3705 - val_loss: 9.1899 - val_acc: 0.3234\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.49922 to 9.18988, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 4/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 11.3293 - acc: 0.25 - ETA: 1s - loss: 8.7161 - acc: 0.4038 - ETA: 1s - loss: 8.8978 - acc: 0.394 - ETA: 1s - loss: 8.7905 - acc: 0.405 - ETA: 1s - loss: 9.0045 - acc: 0.388 - ETA: 1s - loss: 8.8115 - acc: 0.400 - ETA: 1s - loss: 8.5954 - acc: 0.415 - ETA: 1s - loss: 8.6631 - acc: 0.413 - ETA: 1s - loss: 8.5916 - acc: 0.415 - ETA: 0s - loss: 8.6323 - acc: 0.411 - ETA: 0s - loss: 8.6400 - acc: 0.410 - ETA: 0s - loss: 8.6199 - acc: 0.410 - ETA: 0s - loss: 8.5981 - acc: 0.411 - ETA: 0s - loss: 8.6426 - acc: 0.408 - ETA: 0s - loss: 8.6362 - acc: 0.409 - ETA: 0s - loss: 8.5968 - acc: 0.409 - ETA: 0s - loss: 8.6068 - acc: 0.408 - ETA: 0s - loss: 8.5799 - acc: 0.411 - ETA: 0s - loss: 8.5769 - acc: 0.411 - ETA: 0s - loss: 8.5557 - acc: 0.411 - ETA: 0s - loss: 8.5693 - acc: 0.410 - ETA: 0s - loss: 8.5716 - acc: 0.411 - ETA: 0s - loss: 8.5945 - acc: 0.410 - ETA: 0s - loss: 8.5961 - acc: 0.411 - ETA: 0s - loss: 8.5818 - acc: 0.411 - ETA: 0s - loss: 8.5654 - acc: 0.412 - ETA: 0s - loss: 8.5661 - acc: 0.412 - ETA: 0s - loss: 8.5537 - acc: 0.414 - ETA: 0s - loss: 8.5694 - acc: 0.413 - 2s 233us/step - loss: 8.5659 - acc: 0.4139 - val_loss: 8.9772 - val_acc: 0.3533\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.18988 to 8.97721, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 5/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.9033 - acc: 0.350 - ETA: 1s - loss: 9.0072 - acc: 0.395 - ETA: 1s - loss: 8.7682 - acc: 0.410 - ETA: 1s - loss: 8.4938 - acc: 0.434 - ETA: 1s - loss: 8.3725 - acc: 0.433 - ETA: 1s - loss: 8.4875 - acc: 0.431 - ETA: 1s - loss: 8.4766 - acc: 0.432 - ETA: 1s - loss: 8.5454 - acc: 0.425 - ETA: 1s - loss: 8.4579 - acc: 0.430 - ETA: 0s - loss: 8.4330 - acc: 0.433 - ETA: 0s - loss: 8.4233 - acc: 0.433 - ETA: 0s - loss: 8.4261 - acc: 0.433 - ETA: 0s - loss: 8.4178 - acc: 0.436 - ETA: 0s - loss: 8.4900 - acc: 0.432 - ETA: 0s - loss: 8.4469 - acc: 0.433 - ETA: 0s - loss: 8.4507 - acc: 0.433 - ETA: 0s - loss: 8.4831 - acc: 0.431 - ETA: 0s - loss: 8.4813 - acc: 0.431 - ETA: 0s - loss: 8.5349 - acc: 0.428 - ETA: 0s - loss: 8.4959 - acc: 0.431 - ETA: 0s - loss: 8.4665 - acc: 0.434 - ETA: 0s - loss: 8.4668 - acc: 0.435 - ETA: 0s - loss: 8.4361 - acc: 0.437 - ETA: 0s - loss: 8.4520 - acc: 0.435 - ETA: 0s - loss: 8.4153 - acc: 0.436 - ETA: 0s - loss: 8.3915 - acc: 0.437 - ETA: 0s - loss: 8.4092 - acc: 0.436 - ETA: 0s - loss: 8.3817 - acc: 0.438 - 2s 232us/step - loss: 8.3592 - acc: 0.4391 - val_loss: 8.8345 - val_acc: 0.3701\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.97721 to 8.83453, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 6/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.4554 - acc: 0.450 - ETA: 1s - loss: 8.8901 - acc: 0.425 - ETA: 1s - loss: 8.3459 - acc: 0.458 - ETA: 1s - loss: 8.4573 - acc: 0.454 - ETA: 1s - loss: 8.5890 - acc: 0.442 - ETA: 1s - loss: 8.4656 - acc: 0.448 - ETA: 1s - loss: 8.3277 - acc: 0.451 - ETA: 1s - loss: 8.1778 - acc: 0.459 - ETA: 1s - loss: 8.1996 - acc: 0.456 - ETA: 0s - loss: 8.2509 - acc: 0.452 - ETA: 0s - loss: 8.2477 - acc: 0.453 - ETA: 0s - loss: 8.1721 - acc: 0.459 - ETA: 0s - loss: 8.2254 - acc: 0.457 - ETA: 0s - loss: 8.2094 - acc: 0.458 - ETA: 0s - loss: 8.2268 - acc: 0.456 - ETA: 0s - loss: 8.2484 - acc: 0.454 - ETA: 0s - loss: 8.2684 - acc: 0.453 - ETA: 0s - loss: 8.2744 - acc: 0.453 - ETA: 0s - loss: 8.2292 - acc: 0.456 - ETA: 0s - loss: 8.2548 - acc: 0.455 - ETA: 0s - loss: 8.2386 - acc: 0.457 - ETA: 0s - loss: 8.2369 - acc: 0.456 - ETA: 0s - loss: 8.2444 - acc: 0.455 - ETA: 0s - loss: 8.2176 - acc: 0.457 - ETA: 0s - loss: 8.2124 - acc: 0.458 - ETA: 0s - loss: 8.2226 - acc: 0.457 - ETA: 0s - loss: 8.2127 - acc: 0.456 - ETA: 0s - loss: 8.2131 - acc: 0.456 - 2s 233us/step - loss: 8.1896 - acc: 0.4581 - val_loss: 8.6876 - val_acc: 0.3796\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.83453 to 8.68759, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 1s - loss: 11.2854 - acc: 0.30 - ETA: 1s - loss: 9.4483 - acc: 0.4125 - ETA: 1s - loss: 8.7506 - acc: 0.450 - ETA: 1s - loss: 8.5552 - acc: 0.454 - ETA: 1s - loss: 8.3636 - acc: 0.463 - ETA: 1s - loss: 8.2898 - acc: 0.468 - ETA: 1s - loss: 8.1147 - acc: 0.475 - ETA: 1s - loss: 8.1105 - acc: 0.475 - ETA: 1s - loss: 8.1523 - acc: 0.471 - ETA: 1s - loss: 8.1152 - acc: 0.474 - ETA: 0s - loss: 8.0866 - acc: 0.475 - ETA: 0s - loss: 8.1410 - acc: 0.472 - ETA: 0s - loss: 8.1329 - acc: 0.472 - ETA: 0s - loss: 8.1295 - acc: 0.473 - ETA: 0s - loss: 8.0897 - acc: 0.476 - ETA: 0s - loss: 8.1276 - acc: 0.474 - ETA: 0s - loss: 8.1528 - acc: 0.473 - ETA: 0s - loss: 8.1293 - acc: 0.475 - ETA: 0s - loss: 8.1359 - acc: 0.474 - ETA: 0s - loss: 8.1456 - acc: 0.473 - ETA: 0s - loss: 8.1087 - acc: 0.475 - ETA: 0s - loss: 8.1392 - acc: 0.473 - ETA: 0s - loss: 8.1543 - acc: 0.472 - ETA: 0s - loss: 8.1532 - acc: 0.471 - ETA: 0s - loss: 8.1476 - acc: 0.472 - ETA: 0s - loss: 8.1199 - acc: 0.473 - ETA: 0s - loss: 8.1146 - acc: 0.473 - ETA: 0s - loss: 8.1002 - acc: 0.474 - 2s 233us/step - loss: 8.0843 - acc: 0.4757 - val_loss: 8.6497 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.68759 to 8.64972, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 8/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.1572 - acc: 0.450 - ETA: 1s - loss: 7.9332 - acc: 0.484 - ETA: 1s - loss: 8.1211 - acc: 0.472 - ETA: 1s - loss: 8.1125 - acc: 0.477 - ETA: 1s - loss: 8.0564 - acc: 0.482 - ETA: 1s - loss: 8.2237 - acc: 0.471 - ETA: 1s - loss: 8.2302 - acc: 0.471 - ETA: 1s - loss: 8.2113 - acc: 0.474 - ETA: 1s - loss: 8.0812 - acc: 0.478 - ETA: 0s - loss: 8.0963 - acc: 0.478 - ETA: 0s - loss: 8.0614 - acc: 0.479 - ETA: 0s - loss: 8.0803 - acc: 0.478 - ETA: 0s - loss: 8.1005 - acc: 0.477 - ETA: 0s - loss: 8.1036 - acc: 0.477 - ETA: 0s - loss: 8.1196 - acc: 0.475 - ETA: 0s - loss: 8.1277 - acc: 0.474 - ETA: 0s - loss: 8.1329 - acc: 0.474 - ETA: 0s - loss: 8.1403 - acc: 0.472 - ETA: 0s - loss: 8.1120 - acc: 0.474 - ETA: 0s - loss: 8.1116 - acc: 0.472 - ETA: 0s - loss: 8.1215 - acc: 0.472 - ETA: 0s - loss: 8.1066 - acc: 0.472 - ETA: 0s - loss: 8.0935 - acc: 0.473 - ETA: 0s - loss: 8.0539 - acc: 0.476 - ETA: 0s - loss: 8.0587 - acc: 0.475 - ETA: 0s - loss: 8.0202 - acc: 0.477 - ETA: 0s - loss: 7.9791 - acc: 0.479 - ETA: 0s - loss: 8.0124 - acc: 0.477 - 2s 232us/step - loss: 8.0092 - acc: 0.4775 - val_loss: 8.6706 - val_acc: 0.3868\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 8.64972\n",
      "Epoch 9/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 4.8560 - acc: 0.700 - ETA: 1s - loss: 8.0678 - acc: 0.476 - ETA: 1s - loss: 8.0058 - acc: 0.483 - ETA: 1s - loss: 8.0771 - acc: 0.476 - ETA: 1s - loss: 8.0122 - acc: 0.474 - ETA: 1s - loss: 8.0807 - acc: 0.471 - ETA: 1s - loss: 8.0022 - acc: 0.474 - ETA: 1s - loss: 7.9243 - acc: 0.479 - ETA: 1s - loss: 8.0299 - acc: 0.473 - ETA: 0s - loss: 8.0565 - acc: 0.473 - ETA: 0s - loss: 7.9621 - acc: 0.478 - ETA: 0s - loss: 7.9510 - acc: 0.477 - ETA: 0s - loss: 8.0081 - acc: 0.473 - ETA: 0s - loss: 7.9091 - acc: 0.479 - ETA: 0s - loss: 7.8486 - acc: 0.481 - ETA: 0s - loss: 7.8448 - acc: 0.480 - ETA: 0s - loss: 7.7879 - acc: 0.483 - ETA: 0s - loss: 7.8200 - acc: 0.479 - ETA: 0s - loss: 7.8139 - acc: 0.479 - ETA: 0s - loss: 7.7791 - acc: 0.481 - ETA: 0s - loss: 7.7631 - acc: 0.481 - ETA: 0s - loss: 7.7469 - acc: 0.482 - ETA: 0s - loss: 7.7165 - acc: 0.484 - ETA: 0s - loss: 7.7155 - acc: 0.483 - ETA: 0s - loss: 7.7347 - acc: 0.482 - ETA: 0s - loss: 7.7252 - acc: 0.482 - ETA: 0s - loss: 7.7010 - acc: 0.483 - ETA: 0s - loss: 7.6812 - acc: 0.484 - ETA: 0s - loss: 7.6825 - acc: 0.484 - 2s 236us/step - loss: 7.6811 - acc: 0.4847 - val_loss: 8.1810 - val_acc: 0.4048\n",
      "\n",
      "Epoch 00009: val_loss improved from 8.64972 to 8.18104, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 10/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 7.5222 - acc: 0.400 - ETA: 1s - loss: 7.3572 - acc: 0.504 - ETA: 1s - loss: 7.3800 - acc: 0.502 - ETA: 1s - loss: 7.5091 - acc: 0.489 - ETA: 1s - loss: 7.5851 - acc: 0.490 - ETA: 1s - loss: 7.5250 - acc: 0.496 - ETA: 1s - loss: 7.4046 - acc: 0.499 - ETA: 1s - loss: 7.3749 - acc: 0.499 - ETA: 1s - loss: 7.3601 - acc: 0.501 - ETA: 1s - loss: 7.3980 - acc: 0.500 - ETA: 0s - loss: 7.3688 - acc: 0.503 - ETA: 0s - loss: 7.3599 - acc: 0.505 - ETA: 0s - loss: 7.2944 - acc: 0.508 - ETA: 0s - loss: 7.3395 - acc: 0.502 - ETA: 0s - loss: 7.2419 - acc: 0.508 - ETA: 0s - loss: 7.2137 - acc: 0.509 - ETA: 0s - loss: 7.1983 - acc: 0.511 - ETA: 0s - loss: 7.1551 - acc: 0.514 - ETA: 0s - loss: 7.1678 - acc: 0.513 - ETA: 0s - loss: 7.1758 - acc: 0.513 - ETA: 0s - loss: 7.2133 - acc: 0.511 - ETA: 0s - loss: 7.1709 - acc: 0.514 - ETA: 0s - loss: 7.2111 - acc: 0.511 - ETA: 0s - loss: 7.2004 - acc: 0.512 - ETA: 0s - loss: 7.1914 - acc: 0.513 - ETA: 0s - loss: 7.1805 - acc: 0.513 - ETA: 0s - loss: 7.1606 - acc: 0.515 - ETA: 0s - loss: 7.1705 - acc: 0.515 - ETA: 0s - loss: 7.1629 - acc: 0.515 - 2s 235us/step - loss: 7.1656 - acc: 0.5154 - val_loss: 7.8176 - val_acc: 0.4251\n",
      "\n",
      "Epoch 00010: val_loss improved from 8.18104 to 7.81761, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 11/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 4.8360 - acc: 0.700 - ETA: 1s - loss: 6.3134 - acc: 0.595 - ETA: 1s - loss: 6.2967 - acc: 0.575 - ETA: 1s - loss: 6.5315 - acc: 0.566 - ETA: 1s - loss: 6.5704 - acc: 0.561 - ETA: 1s - loss: 6.6825 - acc: 0.558 - ETA: 1s - loss: 6.7448 - acc: 0.554 - ETA: 1s - loss: 6.8110 - acc: 0.549 - ETA: 1s - loss: 6.7479 - acc: 0.551 - ETA: 0s - loss: 6.9155 - acc: 0.541 - ETA: 0s - loss: 6.9464 - acc: 0.537 - ETA: 0s - loss: 6.8835 - acc: 0.542 - ETA: 0s - loss: 6.8288 - acc: 0.546 - ETA: 0s - loss: 6.9158 - acc: 0.539 - ETA: 0s - loss: 6.9352 - acc: 0.538 - ETA: 0s - loss: 6.9083 - acc: 0.540 - ETA: 0s - loss: 6.8968 - acc: 0.541 - ETA: 0s - loss: 6.9171 - acc: 0.541 - ETA: 0s - loss: 6.9535 - acc: 0.537 - ETA: 0s - loss: 6.9469 - acc: 0.537 - ETA: 0s - loss: 6.9437 - acc: 0.537 - ETA: 0s - loss: 6.9465 - acc: 0.537 - ETA: 0s - loss: 6.9157 - acc: 0.539 - ETA: 0s - loss: 6.9339 - acc: 0.538 - ETA: 0s - loss: 6.9106 - acc: 0.539 - ETA: 0s - loss: 6.9103 - acc: 0.540 - ETA: 0s - loss: 6.8998 - acc: 0.541 - ETA: 0s - loss: 6.8965 - acc: 0.540 - ETA: 0s - loss: 6.8950 - acc: 0.540 - 2s 236us/step - loss: 6.8959 - acc: 0.5406 - val_loss: 7.5949 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.81761 to 7.59488, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 12/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 6.4670 - acc: 0.600 - ETA: 1s - loss: 6.9202 - acc: 0.541 - ETA: 1s - loss: 6.8385 - acc: 0.543 - ETA: 1s - loss: 6.6281 - acc: 0.554 - ETA: 1s - loss: 6.7052 - acc: 0.551 - ETA: 1s - loss: 6.7023 - acc: 0.552 - ETA: 1s - loss: 6.8140 - acc: 0.545 - ETA: 1s - loss: 6.8215 - acc: 0.545 - ETA: 1s - loss: 6.7817 - acc: 0.550 - ETA: 1s - loss: 6.8238 - acc: 0.548 - ETA: 0s - loss: 6.7768 - acc: 0.550 - ETA: 0s - loss: 6.8039 - acc: 0.550 - ETA: 0s - loss: 6.8156 - acc: 0.550 - ETA: 0s - loss: 6.7871 - acc: 0.552 - ETA: 0s - loss: 6.8072 - acc: 0.550 - ETA: 0s - loss: 6.7867 - acc: 0.552 - ETA: 0s - loss: 6.7404 - acc: 0.555 - ETA: 0s - loss: 6.7813 - acc: 0.553 - ETA: 0s - loss: 6.7870 - acc: 0.554 - ETA: 0s - loss: 6.8015 - acc: 0.554 - ETA: 0s - loss: 6.7839 - acc: 0.554 - ETA: 0s - loss: 6.7360 - acc: 0.557 - ETA: 0s - loss: 6.7176 - acc: 0.558 - ETA: 0s - loss: 6.7234 - acc: 0.558 - ETA: 0s - loss: 6.7009 - acc: 0.558 - ETA: 0s - loss: 6.7100 - acc: 0.558 - ETA: 0s - loss: 6.6991 - acc: 0.558 - ETA: 0s - loss: 6.6928 - acc: 0.559 - ETA: 0s - loss: 6.7114 - acc: 0.558 - 2s 236us/step - loss: 6.7082 - acc: 0.5585 - val_loss: 7.5923 - val_acc: 0.4395\n",
      "\n",
      "Epoch 00012: val_loss improved from 7.59488 to 7.59230, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 1s - loss: 6.5160 - acc: 0.550 - ETA: 1s - loss: 6.6944 - acc: 0.560 - ETA: 1s - loss: 6.5992 - acc: 0.566 - ETA: 1s - loss: 6.7260 - acc: 0.565 - ETA: 1s - loss: 6.7775 - acc: 0.565 - ETA: 1s - loss: 6.7857 - acc: 0.564 - ETA: 1s - loss: 6.8649 - acc: 0.558 - ETA: 1s - loss: 6.6872 - acc: 0.570 - ETA: 1s - loss: 6.7476 - acc: 0.565 - ETA: 1s - loss: 6.7574 - acc: 0.564 - ETA: 0s - loss: 6.7698 - acc: 0.563 - ETA: 0s - loss: 6.7346 - acc: 0.565 - ETA: 0s - loss: 6.6518 - acc: 0.571 - ETA: 0s - loss: 6.6376 - acc: 0.572 - ETA: 0s - loss: 6.6444 - acc: 0.571 - ETA: 0s - loss: 6.6446 - acc: 0.571 - ETA: 0s - loss: 6.6657 - acc: 0.569 - ETA: 0s - loss: 6.6522 - acc: 0.570 - ETA: 0s - loss: 6.6781 - acc: 0.569 - ETA: 0s - loss: 6.6514 - acc: 0.570 - ETA: 0s - loss: 6.6295 - acc: 0.570 - ETA: 0s - loss: 6.6333 - acc: 0.570 - ETA: 0s - loss: 6.6365 - acc: 0.570 - ETA: 0s - loss: 6.6299 - acc: 0.571 - ETA: 0s - loss: 6.6337 - acc: 0.571 - ETA: 0s - loss: 6.6803 - acc: 0.568 - ETA: 0s - loss: 6.6853 - acc: 0.568 - ETA: 0s - loss: 6.6539 - acc: 0.570 - ETA: 0s - loss: 6.6455 - acc: 0.569 - 2s 237us/step - loss: 6.6426 - acc: 0.5701 - val_loss: 7.5106 - val_acc: 0.4527\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.59230 to 7.51063, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 14/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 4.8446 - acc: 0.700 - ETA: 1s - loss: 6.1682 - acc: 0.611 - ETA: 1s - loss: 6.3078 - acc: 0.602 - ETA: 1s - loss: 6.3953 - acc: 0.595 - ETA: 1s - loss: 6.7901 - acc: 0.567 - ETA: 1s - loss: 6.8598 - acc: 0.560 - ETA: 1s - loss: 7.0287 - acc: 0.550 - ETA: 1s - loss: 6.9827 - acc: 0.553 - ETA: 1s - loss: 6.8807 - acc: 0.560 - ETA: 0s - loss: 6.9243 - acc: 0.557 - ETA: 0s - loss: 6.9459 - acc: 0.555 - ETA: 0s - loss: 6.8461 - acc: 0.563 - ETA: 0s - loss: 6.8131 - acc: 0.565 - ETA: 0s - loss: 6.7867 - acc: 0.567 - ETA: 0s - loss: 6.7332 - acc: 0.570 - ETA: 0s - loss: 6.7440 - acc: 0.570 - ETA: 0s - loss: 6.7732 - acc: 0.568 - ETA: 0s - loss: 6.7984 - acc: 0.566 - ETA: 0s - loss: 6.7883 - acc: 0.566 - ETA: 0s - loss: 6.7408 - acc: 0.569 - ETA: 0s - loss: 6.7232 - acc: 0.570 - ETA: 0s - loss: 6.6917 - acc: 0.572 - ETA: 0s - loss: 6.6522 - acc: 0.574 - ETA: 0s - loss: 6.6612 - acc: 0.574 - ETA: 0s - loss: 6.6467 - acc: 0.575 - ETA: 0s - loss: 6.6519 - acc: 0.574 - ETA: 0s - loss: 6.6368 - acc: 0.575 - ETA: 0s - loss: 6.6336 - acc: 0.574 - ETA: 0s - loss: 6.6119 - acc: 0.575 - 2s 234us/step - loss: 6.5996 - acc: 0.5757 - val_loss: 7.3643 - val_acc: 0.4551\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.51063 to 7.36434, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 15/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.8722 - acc: 0.450 - ETA: 1s - loss: 6.4059 - acc: 0.595 - ETA: 1s - loss: 6.3173 - acc: 0.600 - ETA: 1s - loss: 6.2987 - acc: 0.601 - ETA: 1s - loss: 6.3660 - acc: 0.595 - ETA: 1s - loss: 6.3913 - acc: 0.594 - ETA: 1s - loss: 6.3610 - acc: 0.596 - ETA: 1s - loss: 6.3825 - acc: 0.594 - ETA: 1s - loss: 6.4626 - acc: 0.589 - ETA: 0s - loss: 6.3827 - acc: 0.593 - ETA: 0s - loss: 6.4133 - acc: 0.591 - ETA: 0s - loss: 6.4100 - acc: 0.590 - ETA: 0s - loss: 6.4111 - acc: 0.591 - ETA: 0s - loss: 6.4784 - acc: 0.586 - ETA: 0s - loss: 6.4713 - acc: 0.586 - ETA: 0s - loss: 6.4502 - acc: 0.587 - ETA: 0s - loss: 6.4631 - acc: 0.587 - ETA: 0s - loss: 6.4826 - acc: 0.586 - ETA: 0s - loss: 6.4760 - acc: 0.587 - ETA: 0s - loss: 6.4531 - acc: 0.586 - ETA: 0s - loss: 6.4309 - acc: 0.586 - ETA: 0s - loss: 6.4140 - acc: 0.587 - ETA: 0s - loss: 6.3979 - acc: 0.588 - ETA: 0s - loss: 6.3768 - acc: 0.589 - ETA: 0s - loss: 6.3766 - acc: 0.589 - ETA: 0s - loss: 6.3954 - acc: 0.588 - ETA: 0s - loss: 6.4122 - acc: 0.587 - ETA: 0s - loss: 6.4050 - acc: 0.587 - 2s 233us/step - loss: 6.4240 - acc: 0.5864 - val_loss: 7.3420 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.36434 to 7.34200, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 16/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 6.4473 - acc: 0.600 - ETA: 1s - loss: 6.0003 - acc: 0.615 - ETA: 1s - loss: 6.2807 - acc: 0.596 - ETA: 1s - loss: 6.1557 - acc: 0.605 - ETA: 1s - loss: 6.1597 - acc: 0.606 - ETA: 1s - loss: 6.2954 - acc: 0.597 - ETA: 1s - loss: 6.2276 - acc: 0.601 - ETA: 1s - loss: 6.2567 - acc: 0.601 - ETA: 1s - loss: 6.2580 - acc: 0.600 - ETA: 0s - loss: 6.2776 - acc: 0.598 - ETA: 0s - loss: 6.3727 - acc: 0.592 - ETA: 0s - loss: 6.3007 - acc: 0.598 - ETA: 0s - loss: 6.2066 - acc: 0.604 - ETA: 0s - loss: 6.2148 - acc: 0.603 - ETA: 0s - loss: 6.2580 - acc: 0.600 - ETA: 0s - loss: 6.2840 - acc: 0.598 - ETA: 0s - loss: 6.2687 - acc: 0.599 - ETA: 0s - loss: 6.2453 - acc: 0.600 - ETA: 0s - loss: 6.2511 - acc: 0.599 - ETA: 0s - loss: 6.2799 - acc: 0.597 - ETA: 0s - loss: 6.2824 - acc: 0.597 - ETA: 0s - loss: 6.2610 - acc: 0.598 - ETA: 0s - loss: 6.2468 - acc: 0.599 - ETA: 0s - loss: 6.2492 - acc: 0.599 - ETA: 0s - loss: 6.2222 - acc: 0.601 - ETA: 0s - loss: 6.2435 - acc: 0.600 - ETA: 0s - loss: 6.2515 - acc: 0.599 - ETA: 0s - loss: 6.2720 - acc: 0.598 - ETA: 0s - loss: 6.3091 - acc: 0.596 - 2s 237us/step - loss: 6.3225 - acc: 0.5957 - val_loss: 7.3109 - val_acc: 0.4659\n",
      "\n",
      "Epoch 00016: val_loss improved from 7.34200 to 7.31085, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 17/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.1552 - acc: 0.450 - ETA: 1s - loss: 6.7423 - acc: 0.570 - ETA: 1s - loss: 6.3871 - acc: 0.595 - ETA: 1s - loss: 6.0256 - acc: 0.615 - ETA: 1s - loss: 6.2254 - acc: 0.601 - ETA: 1s - loss: 6.1523 - acc: 0.605 - ETA: 1s - loss: 6.1988 - acc: 0.602 - ETA: 1s - loss: 6.2279 - acc: 0.601 - ETA: 1s - loss: 6.2192 - acc: 0.602 - ETA: 1s - loss: 6.2513 - acc: 0.601 - ETA: 0s - loss: 6.2765 - acc: 0.599 - ETA: 0s - loss: 6.3580 - acc: 0.593 - ETA: 0s - loss: 6.3581 - acc: 0.594 - ETA: 0s - loss: 6.3044 - acc: 0.598 - ETA: 0s - loss: 6.3504 - acc: 0.595 - ETA: 0s - loss: 6.3348 - acc: 0.595 - ETA: 0s - loss: 6.3320 - acc: 0.595 - ETA: 0s - loss: 6.2630 - acc: 0.600 - ETA: 0s - loss: 6.2878 - acc: 0.598 - ETA: 0s - loss: 6.2545 - acc: 0.601 - ETA: 0s - loss: 6.2756 - acc: 0.599 - ETA: 0s - loss: 6.2847 - acc: 0.599 - ETA: 0s - loss: 6.2637 - acc: 0.600 - ETA: 0s - loss: 6.2649 - acc: 0.600 - ETA: 0s - loss: 6.2785 - acc: 0.599 - ETA: 0s - loss: 6.2773 - acc: 0.599 - ETA: 0s - loss: 6.2817 - acc: 0.599 - ETA: 0s - loss: 6.2530 - acc: 0.601 - ETA: 0s - loss: 6.2554 - acc: 0.600 - 2s 236us/step - loss: 6.2657 - acc: 0.6003 - val_loss: 7.1800 - val_acc: 0.4826\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.31085 to 7.17997, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 18/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.1273 - acc: 0.450 - ETA: 1s - loss: 5.8134 - acc: 0.623 - ETA: 1s - loss: 5.7335 - acc: 0.636 - ETA: 1s - loss: 5.8999 - acc: 0.628 - ETA: 1s - loss: 5.9952 - acc: 0.622 - ETA: 1s - loss: 6.0024 - acc: 0.620 - ETA: 1s - loss: 5.9768 - acc: 0.623 - ETA: 1s - loss: 5.8274 - acc: 0.632 - ETA: 1s - loss: 5.8383 - acc: 0.632 - ETA: 0s - loss: 5.9150 - acc: 0.627 - ETA: 0s - loss: 5.9683 - acc: 0.622 - ETA: 0s - loss: 6.0530 - acc: 0.616 - ETA: 0s - loss: 6.0457 - acc: 0.617 - ETA: 0s - loss: 6.0460 - acc: 0.618 - ETA: 0s - loss: 6.1230 - acc: 0.613 - ETA: 0s - loss: 6.1795 - acc: 0.609 - ETA: 0s - loss: 6.1465 - acc: 0.612 - ETA: 0s - loss: 6.1290 - acc: 0.612 - ETA: 0s - loss: 6.1606 - acc: 0.610 - ETA: 0s - loss: 6.1512 - acc: 0.610 - ETA: 0s - loss: 6.1531 - acc: 0.610 - ETA: 0s - loss: 6.1547 - acc: 0.610 - ETA: 0s - loss: 6.1541 - acc: 0.610 - ETA: 0s - loss: 6.1456 - acc: 0.611 - ETA: 0s - loss: 6.1815 - acc: 0.609 - ETA: 0s - loss: 6.1906 - acc: 0.608 - ETA: 0s - loss: 6.2023 - acc: 0.607 - ETA: 0s - loss: 6.1967 - acc: 0.607 - ETA: 0s - loss: 6.2093 - acc: 0.606 - 2s 235us/step - loss: 6.2108 - acc: 0.6069 - val_loss: 7.2729 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.17997\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 1s - loss: 4.0323 - acc: 0.750 - ETA: 1s - loss: 6.0455 - acc: 0.625 - ETA: 1s - loss: 6.0563 - acc: 0.620 - ETA: 1s - loss: 5.9143 - acc: 0.629 - ETA: 1s - loss: 5.9797 - acc: 0.624 - ETA: 1s - loss: 6.1308 - acc: 0.615 - ETA: 1s - loss: 6.0906 - acc: 0.618 - ETA: 1s - loss: 6.0547 - acc: 0.621 - ETA: 1s - loss: 6.1276 - acc: 0.615 - ETA: 0s - loss: 6.1272 - acc: 0.614 - ETA: 0s - loss: 6.1728 - acc: 0.611 - ETA: 0s - loss: 6.1979 - acc: 0.610 - ETA: 0s - loss: 6.1202 - acc: 0.614 - ETA: 0s - loss: 6.1307 - acc: 0.614 - ETA: 0s - loss: 6.1925 - acc: 0.610 - ETA: 0s - loss: 6.1582 - acc: 0.612 - ETA: 0s - loss: 6.1373 - acc: 0.614 - ETA: 0s - loss: 6.0876 - acc: 0.617 - ETA: 0s - loss: 6.0707 - acc: 0.618 - ETA: 0s - loss: 6.1081 - acc: 0.615 - ETA: 0s - loss: 6.1782 - acc: 0.610 - ETA: 0s - loss: 6.1645 - acc: 0.611 - ETA: 0s - loss: 6.1751 - acc: 0.610 - ETA: 0s - loss: 6.1749 - acc: 0.610 - ETA: 0s - loss: 6.1786 - acc: 0.610 - ETA: 0s - loss: 6.1519 - acc: 0.611 - ETA: 0s - loss: 6.1637 - acc: 0.610 - ETA: 0s - loss: 6.1747 - acc: 0.610 - ETA: 0s - loss: 6.1953 - acc: 0.608 - 2s 236us/step - loss: 6.1913 - acc: 0.6093 - val_loss: 7.2290 - val_acc: 0.4766\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.17997\n",
      "Epoch 20/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.0599 - acc: 0.500 - ETA: 1s - loss: 6.9132 - acc: 0.569 - ETA: 1s - loss: 7.1183 - acc: 0.555 - ETA: 1s - loss: 6.5912 - acc: 0.586 - ETA: 1s - loss: 6.4438 - acc: 0.596 - ETA: 1s - loss: 6.4046 - acc: 0.600 - ETA: 1s - loss: 6.4342 - acc: 0.598 - ETA: 1s - loss: 6.4200 - acc: 0.598 - ETA: 1s - loss: 6.4070 - acc: 0.599 - ETA: 1s - loss: 6.3604 - acc: 0.602 - ETA: 0s - loss: 6.2948 - acc: 0.605 - ETA: 0s - loss: 6.2518 - acc: 0.608 - ETA: 0s - loss: 6.2885 - acc: 0.606 - ETA: 0s - loss: 6.3100 - acc: 0.605 - ETA: 0s - loss: 6.2828 - acc: 0.606 - ETA: 0s - loss: 6.2222 - acc: 0.610 - ETA: 0s - loss: 6.2163 - acc: 0.609 - ETA: 0s - loss: 6.1741 - acc: 0.612 - ETA: 0s - loss: 6.1288 - acc: 0.615 - ETA: 0s - loss: 6.1202 - acc: 0.615 - ETA: 0s - loss: 6.0845 - acc: 0.617 - ETA: 0s - loss: 6.1179 - acc: 0.615 - ETA: 0s - loss: 6.1366 - acc: 0.614 - ETA: 0s - loss: 6.1567 - acc: 0.612 - ETA: 0s - loss: 6.1586 - acc: 0.612 - ETA: 0s - loss: 6.1711 - acc: 0.611 - ETA: 0s - loss: 6.1636 - acc: 0.612 - ETA: 0s - loss: 6.1622 - acc: 0.612 - ETA: 0s - loss: 6.1763 - acc: 0.611 - 2s 238us/step - loss: 6.1716 - acc: 0.6114 - val_loss: 7.1781 - val_acc: 0.4826\n",
      "\n",
      "Epoch 00020: val_loss improved from 7.17997 to 7.17806, saving model to saved_models/weights.best.VGG16.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dcda3b38d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 训练模型\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, \n",
    "          validation_data=(valid_VGG16, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载具有最好验证loss的模型\n",
    "\n",
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型\n",
    "现在，我们可以测试此CNN在狗图像测试数据集中识别品种的效果如何。我们在下方打印出测试准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 47.2488%\n"
     ]
    }
   ],
   "source": [
    "# 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用模型预测狗的品种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def VGG16_predict_breed(img_path):\n",
    "    # 提取bottleneck特征\n",
    "    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "    # 获取预测向量\n",
    "    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
    "    # 返回此模型预测的狗的品种\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## 步骤 5: 建立一个CNN来分类狗的品种（使用迁移学习）\n",
    "\n",
    "现在你将使用迁移学习来建立一个CNN，从而可以从图像中识别狗的品种。你的 CNN 在测试集上的准确率必须至少达到60%。\n",
    "\n",
    "在步骤4中，我们使用了迁移学习来创建一个使用基于 VGG-16 提取的特征向量来搭建一个 CNN。在本部分内容中，你必须使用另一个预训练模型来搭建一个 CNN。为了让这个任务更易实现，我们已经预先对目前 keras 中可用的几种网络进行了预训练：\n",
    "\n",
    "- [VGG-19](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/DLND+documents/DogVGG19Data.npz) bottleneck features\n",
    "- [ResNet-50](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/DLND+documents/DogResnet50Data.npz) bottleneck features\n",
    "- [Inception](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/DLND+documents/DogInceptionV3Data.npz) bottleneck features\n",
    "- [Xception](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/DLND+documents/DogXceptionData.npz) bottleneck features\n",
    "\n",
    "这些文件被命名为为：\n",
    "\n",
    "    Dog{network}Data.npz\n",
    "\n",
    "其中 `{network}` 可以是 `VGG19`、`Resnet50`、`InceptionV3` 或 `Xception` 中的一个。选择上方网络架构中的一个，下载相对应的bottleneck特征，并将所下载的文件保存在目录 `bottleneck_features/` 中。\n",
    "\n",
    "\n",
    "### 【练习】获取模型的特征向量\n",
    "\n",
    "在下方代码块中，通过运行下方代码提取训练、测试与验证集相对应的bottleneck特征。\n",
    "\n",
    "    bottleneck_features = np.load('bottleneck_features/Dog{network}Data.npz')\n",
    "    train_{network} = bottleneck_features['train']\n",
    "    valid_{network} = bottleneck_features['valid']\n",
    "    test_{network} = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 从另一个预训练的CNN获取bottleneck特征\n",
    "bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')\n",
    "train_model = bottleneck_features['train']\n",
    "valid_model = bottleneck_features['valid']\n",
    "test_model = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【练习】模型架构\n",
    "\n",
    "建立一个CNN来分类狗品种。在你的代码单元块的最后，通过运行如下代码输出网络的结构：\n",
    "    \n",
    "        <your model's name>.summary()\n",
    "   \n",
    "---\n",
    "\n",
    "<a id='question6'></a>  \n",
    "\n",
    "### __问题 6:__ \n",
    "\n",
    "\n",
    "在下方的代码块中尝试使用 Keras 搭建最终的网络架构，并回答你实现最终 CNN 架构的步骤与每一步的作用，并描述你在迁移学习过程中，使用该网络架构的原因。\n",
    "\n",
    "\n",
    "__回答:__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### TODO: 定义你的框架\n",
    "my_model = Sequential()\n",
    "my_model.add(GlobalAveragePooling2D(input_shape=train_model.shape[1:]))\n",
    "my_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 编译模型\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 【练习】训练模型\n",
    "\n",
    "<a id='question7'></a>  \n",
    "\n",
    "### __问题 7:__ \n",
    "\n",
    "在下方代码单元中训练你的模型。使用模型检查点（model checkpointing）来储存具有最低验证集 loss 的模型。\n",
    "\n",
    "当然，你也可以对训练集进行 [数据增强](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) 以优化模型的表现，不过这不是必须的步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "6680/6680 [==============================] - ETA: 3:39 - loss: 5.2723 - acc: 0.0000e+0 - ETA: 13s - loss: 5.2835 - acc: 0.0941    - ETA: 6s - loss: 4.5592 - acc: 0.1586 - ETA: 4s - loss: 3.9050 - acc: 0.241 - ETA: 3s - loss: 3.4637 - acc: 0.285 - ETA: 2s - loss: 3.1756 - acc: 0.327 - ETA: 2s - loss: 2.8993 - acc: 0.375 - ETA: 1s - loss: 2.6781 - acc: 0.414 - ETA: 1s - loss: 2.5045 - acc: 0.446 - ETA: 1s - loss: 2.3552 - acc: 0.471 - ETA: 1s - loss: 2.2340 - acc: 0.492 - ETA: 0s - loss: 2.1211 - acc: 0.512 - ETA: 0s - loss: 2.0206 - acc: 0.529 - ETA: 0s - loss: 1.9370 - acc: 0.545 - ETA: 0s - loss: 1.8610 - acc: 0.559 - ETA: 0s - loss: 1.7940 - acc: 0.571 - ETA: 0s - loss: 1.7354 - acc: 0.582 - ETA: 0s - loss: 1.6804 - acc: 0.591 - ETA: 0s - loss: 1.6314 - acc: 0.601 - 2s 263us/step - loss: 1.6035 - acc: 0.6060 - val_loss: 0.8202 - val_acc: 0.7329\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82017, saving model to saved_models/weights.best.my_model.hdf5\n",
      "Epoch 2/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.3174 - acc: 0.950 - ETA: 1s - loss: 0.3591 - acc: 0.893 - ETA: 0s - loss: 0.3935 - acc: 0.879 - ETA: 0s - loss: 0.3955 - acc: 0.887 - ETA: 0s - loss: 0.4316 - acc: 0.872 - ETA: 0s - loss: 0.4341 - acc: 0.869 - ETA: 0s - loss: 0.4432 - acc: 0.867 - ETA: 0s - loss: 0.4391 - acc: 0.868 - ETA: 0s - loss: 0.4401 - acc: 0.868 - ETA: 0s - loss: 0.4344 - acc: 0.869 - ETA: 0s - loss: 0.4316 - acc: 0.869 - ETA: 0s - loss: 0.4319 - acc: 0.867 - ETA: 0s - loss: 0.4387 - acc: 0.865 - ETA: 0s - loss: 0.4425 - acc: 0.864 - ETA: 0s - loss: 0.4400 - acc: 0.864 - ETA: 0s - loss: 0.4381 - acc: 0.865 - ETA: 0s - loss: 0.4316 - acc: 0.866 - ETA: 0s - loss: 0.4361 - acc: 0.864 - ETA: 0s - loss: 0.4321 - acc: 0.865 - 1s 152us/step - loss: 0.4319 - acc: 0.8641 - val_loss: 0.6575 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82017 to 0.65748, saving model to saved_models/weights.best.my_model.hdf5\n",
      "Epoch 3/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.1138 - acc: 0.950 - ETA: 0s - loss: 0.2014 - acc: 0.941 - ETA: 0s - loss: 0.1842 - acc: 0.944 - ETA: 0s - loss: 0.2021 - acc: 0.938 - ETA: 0s - loss: 0.2223 - acc: 0.936 - ETA: 0s - loss: 0.2241 - acc: 0.934 - ETA: 0s - loss: 0.2296 - acc: 0.930 - ETA: 0s - loss: 0.2355 - acc: 0.926 - ETA: 0s - loss: 0.2345 - acc: 0.927 - ETA: 0s - loss: 0.2384 - acc: 0.925 - ETA: 0s - loss: 0.2448 - acc: 0.922 - ETA: 0s - loss: 0.2503 - acc: 0.921 - ETA: 0s - loss: 0.2500 - acc: 0.921 - ETA: 0s - loss: 0.2495 - acc: 0.921 - ETA: 0s - loss: 0.2518 - acc: 0.918 - ETA: 0s - loss: 0.2589 - acc: 0.917 - ETA: 0s - loss: 0.2582 - acc: 0.917 - ETA: 0s - loss: 0.2598 - acc: 0.916 - ETA: 0s - loss: 0.2629 - acc: 0.915 - 1s 148us/step - loss: 0.2618 - acc: 0.9159 - val_loss: 0.6303 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65748 to 0.63028, saving model to saved_models/weights.best.my_model.hdf5\n",
      "Epoch 4/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.2897 - acc: 0.950 - ETA: 0s - loss: 0.1680 - acc: 0.955 - ETA: 0s - loss: 0.1536 - acc: 0.952 - ETA: 0s - loss: 0.1631 - acc: 0.951 - ETA: 0s - loss: 0.1582 - acc: 0.952 - ETA: 0s - loss: 0.1667 - acc: 0.951 - ETA: 0s - loss: 0.1653 - acc: 0.951 - ETA: 0s - loss: 0.1729 - acc: 0.946 - ETA: 0s - loss: 0.1642 - acc: 0.950 - ETA: 0s - loss: 0.1628 - acc: 0.951 - ETA: 0s - loss: 0.1641 - acc: 0.951 - ETA: 0s - loss: 0.1673 - acc: 0.951 - ETA: 0s - loss: 0.1704 - acc: 0.949 - ETA: 0s - loss: 0.1721 - acc: 0.948 - ETA: 0s - loss: 0.1733 - acc: 0.948 - ETA: 0s - loss: 0.1747 - acc: 0.947 - ETA: 0s - loss: 0.1785 - acc: 0.947 - ETA: 0s - loss: 0.1762 - acc: 0.947 - ETA: 0s - loss: 0.1770 - acc: 0.947 - 1s 147us/step - loss: 0.1766 - acc: 0.9470 - val_loss: 0.6082 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63028 to 0.60815, saving model to saved_models/weights.best.my_model.hdf5\n",
      "Epoch 5/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0751 - acc: 1.000 - ETA: 0s - loss: 0.0747 - acc: 0.981 - ETA: 0s - loss: 0.1007 - acc: 0.967 - ETA: 0s - loss: 0.1005 - acc: 0.968 - ETA: 0s - loss: 0.1058 - acc: 0.967 - ETA: 0s - loss: 0.1172 - acc: 0.962 - ETA: 0s - loss: 0.1129 - acc: 0.964 - ETA: 0s - loss: 0.1152 - acc: 0.963 - ETA: 0s - loss: 0.1104 - acc: 0.964 - ETA: 0s - loss: 0.1091 - acc: 0.964 - ETA: 0s - loss: 0.1082 - acc: 0.964 - ETA: 0s - loss: 0.1109 - acc: 0.964 - ETA: 0s - loss: 0.1116 - acc: 0.964 - ETA: 0s - loss: 0.1124 - acc: 0.963 - ETA: 0s - loss: 0.1138 - acc: 0.963 - ETA: 0s - loss: 0.1156 - acc: 0.963 - ETA: 0s - loss: 0.1181 - acc: 0.962 - ETA: 0s - loss: 0.1206 - acc: 0.961 - ETA: 0s - loss: 0.1226 - acc: 0.961 - 1s 146us/step - loss: 0.1225 - acc: 0.9611 - val_loss: 0.6650 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.60815\n",
      "Epoch 6/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0392 - acc: 1.000 - ETA: 0s - loss: 0.0608 - acc: 0.981 - ETA: 0s - loss: 0.0683 - acc: 0.979 - ETA: 0s - loss: 0.0659 - acc: 0.981 - ETA: 0s - loss: 0.0668 - acc: 0.983 - ETA: 0s - loss: 0.0778 - acc: 0.976 - ETA: 0s - loss: 0.0746 - acc: 0.977 - ETA: 0s - loss: 0.0762 - acc: 0.976 - ETA: 0s - loss: 0.0779 - acc: 0.976 - ETA: 0s - loss: 0.0780 - acc: 0.976 - ETA: 0s - loss: 0.0797 - acc: 0.975 - ETA: 0s - loss: 0.0798 - acc: 0.975 - ETA: 0s - loss: 0.0814 - acc: 0.975 - ETA: 0s - loss: 0.0803 - acc: 0.976 - ETA: 0s - loss: 0.0839 - acc: 0.974 - ETA: 0s - loss: 0.0834 - acc: 0.973 - ETA: 0s - loss: 0.0859 - acc: 0.973 - ETA: 0s - loss: 0.0888 - acc: 0.972 - 1s 144us/step - loss: 0.0889 - acc: 0.9722 - val_loss: 0.6690 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.60815\n",
      "Epoch 7/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0368 - acc: 1.000 - ETA: 0s - loss: 0.0494 - acc: 0.990 - ETA: 0s - loss: 0.0493 - acc: 0.989 - ETA: 0s - loss: 0.0487 - acc: 0.986 - ETA: 0s - loss: 0.0529 - acc: 0.983 - ETA: 0s - loss: 0.0495 - acc: 0.984 - ETA: 0s - loss: 0.0492 - acc: 0.984 - ETA: 0s - loss: 0.0508 - acc: 0.983 - ETA: 0s - loss: 0.0511 - acc: 0.983 - ETA: 0s - loss: 0.0534 - acc: 0.982 - ETA: 0s - loss: 0.0565 - acc: 0.981 - ETA: 0s - loss: 0.0557 - acc: 0.982 - ETA: 0s - loss: 0.0559 - acc: 0.982 - ETA: 0s - loss: 0.0581 - acc: 0.981 - ETA: 0s - loss: 0.0597 - acc: 0.981 - ETA: 0s - loss: 0.0608 - acc: 0.982 - ETA: 0s - loss: 0.0607 - acc: 0.982 - ETA: 0s - loss: 0.0613 - acc: 0.982 - ETA: 0s - loss: 0.0613 - acc: 0.982 - 1s 150us/step - loss: 0.0621 - acc: 0.9817 - val_loss: 0.6452 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60815\n",
      "Epoch 8/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0123 - acc: 1.000 - ETA: 0s - loss: 0.0294 - acc: 0.988 - ETA: 0s - loss: 0.0235 - acc: 0.994 - ETA: 0s - loss: 0.0374 - acc: 0.991 - ETA: 0s - loss: 0.0380 - acc: 0.990 - ETA: 0s - loss: 0.0354 - acc: 0.992 - ETA: 0s - loss: 0.0366 - acc: 0.990 - ETA: 0s - loss: 0.0408 - acc: 0.989 - ETA: 0s - loss: 0.0422 - acc: 0.989 - ETA: 0s - loss: 0.0426 - acc: 0.989 - ETA: 0s - loss: 0.0420 - acc: 0.989 - ETA: 0s - loss: 0.0438 - acc: 0.989 - ETA: 0s - loss: 0.0462 - acc: 0.988 - ETA: 0s - loss: 0.0450 - acc: 0.988 - ETA: 0s - loss: 0.0463 - acc: 0.987 - ETA: 0s - loss: 0.0467 - acc: 0.988 - ETA: 0s - loss: 0.0462 - acc: 0.988 - ETA: 0s - loss: 0.0461 - acc: 0.988 - ETA: 0s - loss: 0.0469 - acc: 0.988 - 1s 149us/step - loss: 0.0491 - acc: 0.9879 - val_loss: 0.6833 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60815\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 0s - loss: 0.0058 - acc: 1.000 - ETA: 0s - loss: 0.0155 - acc: 1.000 - ETA: 0s - loss: 0.0202 - acc: 0.994 - ETA: 0s - loss: 0.0263 - acc: 0.992 - ETA: 0s - loss: 0.0289 - acc: 0.992 - ETA: 0s - loss: 0.0297 - acc: 0.993 - ETA: 0s - loss: 0.0303 - acc: 0.992 - ETA: 0s - loss: 0.0301 - acc: 0.993 - ETA: 0s - loss: 0.0310 - acc: 0.992 - ETA: 0s - loss: 0.0305 - acc: 0.992 - ETA: 0s - loss: 0.0305 - acc: 0.991 - ETA: 0s - loss: 0.0310 - acc: 0.991 - ETA: 0s - loss: 0.0319 - acc: 0.991 - ETA: 0s - loss: 0.0328 - acc: 0.990 - ETA: 0s - loss: 0.0328 - acc: 0.990 - ETA: 0s - loss: 0.0329 - acc: 0.990 - ETA: 0s - loss: 0.0332 - acc: 0.991 - ETA: 0s - loss: 0.0349 - acc: 0.990 - ETA: 0s - loss: 0.0360 - acc: 0.990 - 1s 150us/step - loss: 0.0358 - acc: 0.9906 - val_loss: 0.6855 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.60815\n",
      "Epoch 10/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0040 - acc: 1.000 - ETA: 0s - loss: 0.0084 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 0.995 - ETA: 0s - loss: 0.0183 - acc: 0.995 - ETA: 0s - loss: 0.0218 - acc: 0.994 - ETA: 0s - loss: 0.0193 - acc: 0.995 - ETA: 0s - loss: 0.0191 - acc: 0.995 - ETA: 0s - loss: 0.0222 - acc: 0.994 - ETA: 0s - loss: 0.0245 - acc: 0.993 - ETA: 0s - loss: 0.0249 - acc: 0.993 - ETA: 0s - loss: 0.0267 - acc: 0.993 - ETA: 0s - loss: 0.0265 - acc: 0.993 - ETA: 0s - loss: 0.0258 - acc: 0.993 - ETA: 0s - loss: 0.0263 - acc: 0.992 - ETA: 0s - loss: 0.0258 - acc: 0.993 - ETA: 0s - loss: 0.0269 - acc: 0.993 - ETA: 0s - loss: 0.0280 - acc: 0.992 - ETA: 0s - loss: 0.0277 - acc: 0.992 - ETA: 0s - loss: 0.0274 - acc: 0.992 - 1s 154us/step - loss: 0.0278 - acc: 0.9928 - val_loss: 0.7204 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60815\n",
      "Epoch 11/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0228 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0093 - acc: 0.998 - ETA: 0s - loss: 0.0094 - acc: 0.999 - ETA: 0s - loss: 0.0125 - acc: 0.998 - ETA: 0s - loss: 0.0149 - acc: 0.997 - ETA: 0s - loss: 0.0155 - acc: 0.997 - ETA: 0s - loss: 0.0150 - acc: 0.997 - ETA: 0s - loss: 0.0170 - acc: 0.997 - ETA: 0s - loss: 0.0210 - acc: 0.995 - ETA: 0s - loss: 0.0213 - acc: 0.995 - ETA: 0s - loss: 0.0208 - acc: 0.995 - ETA: 0s - loss: 0.0199 - acc: 0.996 - ETA: 0s - loss: 0.0195 - acc: 0.996 - ETA: 0s - loss: 0.0204 - acc: 0.995 - ETA: 0s - loss: 0.0203 - acc: 0.995 - ETA: 0s - loss: 0.0203 - acc: 0.995 - ETA: 0s - loss: 0.0201 - acc: 0.995 - ETA: 0s - loss: 0.0201 - acc: 0.995 - 1s 151us/step - loss: 0.0207 - acc: 0.9955 - val_loss: 0.7805 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.60815\n",
      "Epoch 12/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 1s - loss: 0.0080 - acc: 1.000 - ETA: 0s - loss: 0.0268 - acc: 0.994 - ETA: 0s - loss: 0.0208 - acc: 0.996 - ETA: 0s - loss: 0.0185 - acc: 0.996 - ETA: 0s - loss: 0.0165 - acc: 0.997 - ETA: 0s - loss: 0.0160 - acc: 0.996 - ETA: 0s - loss: 0.0164 - acc: 0.996 - ETA: 0s - loss: 0.0170 - acc: 0.995 - ETA: 0s - loss: 0.0161 - acc: 0.995 - ETA: 0s - loss: 0.0174 - acc: 0.995 - ETA: 0s - loss: 0.0183 - acc: 0.995 - ETA: 0s - loss: 0.0193 - acc: 0.995 - ETA: 0s - loss: 0.0185 - acc: 0.995 - ETA: 0s - loss: 0.0186 - acc: 0.995 - ETA: 0s - loss: 0.0190 - acc: 0.994 - ETA: 0s - loss: 0.0185 - acc: 0.995 - ETA: 0s - loss: 0.0185 - acc: 0.995 - ETA: 0s - loss: 0.0177 - acc: 0.995 - 1s 152us/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.7751 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60815\n",
      "Epoch 13/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 4.4096e-04 - acc: 1.000 - ETA: 0s - loss: 0.0046 - acc: 1.0000    - ETA: 0s - loss: 0.0164 - acc: 0.997 - ETA: 0s - loss: 0.0135 - acc: 0.998 - ETA: 0s - loss: 0.0112 - acc: 0.998 - ETA: 0s - loss: 0.0105 - acc: 0.998 - ETA: 0s - loss: 0.0138 - acc: 0.998 - ETA: 0s - loss: 0.0131 - acc: 0.997 - ETA: 0s - loss: 0.0130 - acc: 0.997 - ETA: 0s - loss: 0.0119 - acc: 0.998 - ETA: 0s - loss: 0.0111 - acc: 0.998 - ETA: 0s - loss: 0.0106 - acc: 0.998 - ETA: 0s - loss: 0.0108 - acc: 0.998 - ETA: 0s - loss: 0.0111 - acc: 0.998 - ETA: 0s - loss: 0.0112 - acc: 0.997 - ETA: 0s - loss: 0.0127 - acc: 0.997 - ETA: 0s - loss: 0.0142 - acc: 0.997 - ETA: 0s - loss: 0.0141 - acc: 0.997 - ETA: 0s - loss: 0.0142 - acc: 0.997 - ETA: 0s - loss: 0.0147 - acc: 0.996 - 1s 155us/step - loss: 0.0147 - acc: 0.9969 - val_loss: 0.8205 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60815\n",
      "Epoch 14/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0038 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 0.999 - ETA: 0s - loss: 0.0045 - acc: 0.999 - ETA: 0s - loss: 0.0044 - acc: 0.999 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0067 - acc: 0.998 - ETA: 0s - loss: 0.0074 - acc: 0.998 - ETA: 0s - loss: 0.0070 - acc: 0.998 - ETA: 0s - loss: 0.0070 - acc: 0.998 - ETA: 0s - loss: 0.0096 - acc: 0.998 - ETA: 0s - loss: 0.0105 - acc: 0.997 - ETA: 0s - loss: 0.0115 - acc: 0.997 - ETA: 0s - loss: 0.0112 - acc: 0.997 - ETA: 0s - loss: 0.0122 - acc: 0.997 - 1s 151us/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.8230 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60815\n",
      "Epoch 15/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - ETA: 0s - loss: 0.0194 - acc: 0.991 - ETA: 0s - loss: 0.0138 - acc: 0.994 - ETA: 0s - loss: 0.0110 - acc: 0.996 - ETA: 0s - loss: 0.0090 - acc: 0.997 - ETA: 0s - loss: 0.0083 - acc: 0.997 - ETA: 0s - loss: 0.0073 - acc: 0.997 - ETA: 0s - loss: 0.0074 - acc: 0.997 - ETA: 0s - loss: 0.0067 - acc: 0.997 - ETA: 0s - loss: 0.0063 - acc: 0.998 - ETA: 0s - loss: 0.0061 - acc: 0.998 - ETA: 0s - loss: 0.0057 - acc: 0.998 - ETA: 0s - loss: 0.0073 - acc: 0.998 - ETA: 0s - loss: 0.0074 - acc: 0.998 - ETA: 0s - loss: 0.0072 - acc: 0.998 - ETA: 0s - loss: 0.0070 - acc: 0.998 - ETA: 0s - loss: 0.0069 - acc: 0.998 - ETA: 0s - loss: 0.0069 - acc: 0.998 - ETA: 0s - loss: 0.0089 - acc: 0.997 - 1s 152us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.8364 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60815\n",
      "Epoch 16/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 3.2312e-04 - acc: 1.000 - ETA: 1s - loss: 9.7581e-04 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 0.9985    - ETA: 0s - loss: 0.0074 - acc: 0.998 - ETA: 0s - loss: 0.0060 - acc: 0.998 - ETA: 0s - loss: 0.0062 - acc: 0.997 - ETA: 0s - loss: 0.0059 - acc: 0.998 - ETA: 0s - loss: 0.0064 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0059 - acc: 0.998 - ETA: 0s - loss: 0.0056 - acc: 0.998 - ETA: 0s - loss: 0.0061 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0068 - acc: 0.997 - ETA: 0s - loss: 0.0089 - acc: 0.997 - ETA: 0s - loss: 0.0088 - acc: 0.997 - ETA: 0s - loss: 0.0084 - acc: 0.997 - ETA: 0s - loss: 0.0082 - acc: 0.997 - ETA: 0s - loss: 0.0090 - acc: 0.997 - 1s 150us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.8314 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60815\n",
      "Epoch 17/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 0.0230 - acc: 1.000 - ETA: 0s - loss: 0.0138 - acc: 0.994 - ETA: 0s - loss: 0.0151 - acc: 0.994 - ETA: 0s - loss: 0.0120 - acc: 0.994 - ETA: 0s - loss: 0.0096 - acc: 0.996 - ETA: 0s - loss: 0.0095 - acc: 0.996 - ETA: 0s - loss: 0.0084 - acc: 0.996 - ETA: 0s - loss: 0.0081 - acc: 0.996 - ETA: 0s - loss: 0.0073 - acc: 0.997 - ETA: 0s - loss: 0.0069 - acc: 0.997 - ETA: 0s - loss: 0.0063 - acc: 0.997 - ETA: 0s - loss: 0.0062 - acc: 0.997 - ETA: 0s - loss: 0.0066 - acc: 0.997 - ETA: 0s - loss: 0.0086 - acc: 0.997 - ETA: 0s - loss: 0.0081 - acc: 0.997 - ETA: 0s - loss: 0.0077 - acc: 0.998 - ETA: 0s - loss: 0.0077 - acc: 0.998 - ETA: 0s - loss: 0.0075 - acc: 0.998 - ETA: 0s - loss: 0.0080 - acc: 0.997 - 1s 146us/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.8579 - val_acc: 0.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60815\n",
      "Epoch 18/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0161 - acc: 0.997 - ETA: 0s - loss: 0.0172 - acc: 0.995 - ETA: 0s - loss: 0.0133 - acc: 0.996 - ETA: 0s - loss: 0.0107 - acc: 0.997 - ETA: 0s - loss: 0.0089 - acc: 0.997 - ETA: 0s - loss: 0.0083 - acc: 0.997 - ETA: 0s - loss: 0.0073 - acc: 0.998 - ETA: 0s - loss: 0.0069 - acc: 0.998 - ETA: 0s - loss: 0.0063 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0054 - acc: 0.998 - ETA: 0s - loss: 0.0051 - acc: 0.998 - ETA: 0s - loss: 0.0052 - acc: 0.998 - ETA: 0s - loss: 0.0051 - acc: 0.998 - ETA: 0s - loss: 0.0061 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0064 - acc: 0.998 - ETA: 0s - loss: 0.0062 - acc: 0.998 - 1s 150us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.8646 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60815\n",
      "Epoch 19/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 7.2494e-05 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 0.9972    - ETA: 0s - loss: 0.0031 - acc: 0.998 - ETA: 0s - loss: 0.0071 - acc: 0.997 - ETA: 0s - loss: 0.0054 - acc: 0.998 - ETA: 0s - loss: 0.0049 - acc: 0.998 - ETA: 0s - loss: 0.0043 - acc: 0.998 - ETA: 0s - loss: 0.0053 - acc: 0.998 - ETA: 0s - loss: 0.0048 - acc: 0.998 - ETA: 0s - loss: 0.0064 - acc: 0.997 - ETA: 0s - loss: 0.0078 - acc: 0.997 - ETA: 0s - loss: 0.0072 - acc: 0.997 - ETA: 0s - loss: 0.0068 - acc: 0.997 - ETA: 0s - loss: 0.0063 - acc: 0.998 - ETA: 0s - loss: 0.0060 - acc: 0.998 - ETA: 0s - loss: 0.0057 - acc: 0.998 - ETA: 0s - loss: 0.0057 - acc: 0.998 - ETA: 0s - loss: 0.0055 - acc: 0.998 - ETA: 0s - loss: 0.0052 - acc: 0.998 - 1s 150us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.8597 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.60815\n",
      "Epoch 20/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 1.8318e-04 - acc: 1.000 - ETA: 0s - loss: 3.7323e-04 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.0000    - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 8.9309e-04 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 0.9994    - ETA: 0s - loss: 0.0019 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0023 - acc: 0.999 - ETA: 0s - loss: 0.0064 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0067 - acc: 0.998 - ETA: 0s - loss: 0.0062 - acc: 0.998 - ETA: 0s - loss: 0.0057 - acc: 0.998 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0056 - acc: 0.998 - ETA: 0s - loss: 0.0055 - acc: 0.998 - ETA: 0s - loss: 0.0053 - acc: 0.998 - ETA: 0s - loss: 0.0068 - acc: 0.998 - 1s 150us/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.9114 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de9ad313c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: 训练模型\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.my_model.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "my_model.fit(train_model, train_targets, \n",
    "          validation_data=(valid_model, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 加载具有最佳验证loss的模型权重\n",
    "\n",
    "my_model.load_weights('saved_models/weights.best.my_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 【练习】测试模型\n",
    "\n",
    "<a id='question8'></a>  \n",
    "\n",
    "### __问题 8:__ \n",
    "\n",
    "在狗图像的测试数据集上试用你的模型。确保测试准确率大于60%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 81.5789%\n"
     ]
    }
   ],
   "source": [
    "### TODO: 在测试集上计算分类准确率\n",
    "\n",
    "# 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "my_model_predictions = [np.argmax(my_model.predict(np.expand_dims(feature, axis=0))) for feature in test_model]\n",
    "\n",
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(my_model_predictions)==np.argmax(test_targets, axis=1))/len(my_model_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 【练习】使用模型测试狗的品种\n",
    "\n",
    "\n",
    "实现一个函数，它的输入为图像路径，功能为预测对应图像的类别，输出为你模型预测出的狗类别（`Affenpinscher`, `Afghan_hound` 等）。\n",
    "\n",
    "与步骤5中的模拟函数类似，你的函数应当包含如下三个步骤：\n",
    "\n",
    "1. 根据选定的模型载入图像特征（bottleneck features）\n",
    "2. 将图像特征输输入到你的模型中，并返回预测向量。注意，在该向量上使用 argmax 函数可以返回狗种类的序号。\n",
    "3. 使用在步骤0中定义的 `dog_names` 数组来返回对应的狗种类名称。\n",
    "\n",
    "提取图像特征过程中使用到的函数可以在 `extract_bottleneck_features.py` 中找到。同时，他们应已在之前的代码块中被导入。根据你选定的 CNN 网络，你可以使用 `extract_{network}` 函数来获得对应的图像特征，其中 `{network}` 代表 `VGG19`, `Resnet50`, `InceptionV3`, 或 `Xception` 中的一个。\n",
    " \n",
    "---\n",
    "\n",
    "<a id='question9'></a>  \n",
    "\n",
    "### __问题 9:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 写一个函数，该函数将图像的路径作为输入\n",
    "### 然后返回此模型所预测的狗的品种\n",
    "\n",
    "def my_model_predict_breed(img_path):\n",
    "    # 提取bottleneck特征\n",
    "    bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "    # 获取预测向量\n",
    "    predicted_vector = my_model.predict(bottleneck_feature)\n",
    "    # 返回此模型预测的狗的品种\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='step6'></a>\n",
    "## 步骤 6: 完成你的算法\n",
    "\n",
    "\n",
    "\n",
    "实现一个算法，它的输入为图像的路径，它能够区分图像是否包含一个人、狗或两者都不包含，然后：\n",
    "\n",
    "- 如果从图像中检测到一只__狗__，返回被预测的品种。\n",
    "- 如果从图像中检测到__人__，返回最相像的狗品种。\n",
    "- 如果两者都不能在图像中检测到，输出错误提示。\n",
    "\n",
    "我们非常欢迎你来自己编写检测图像中人类与狗的函数，你可以随意地使用上方完成的 `face_detector` 和 `dog_detector` 函数。你__需要__在步骤5使用你的CNN来预测狗品种。\n",
    "\n",
    "下面提供了算法的示例输出，但你可以自由地设计自己的模型！\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id='question10'></a>  \n",
    "\n",
    "### __问题 10:__\n",
    "\n",
    "在下方代码块中完成你的代码。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 设计你的算法\n",
    "### 自由地使用所需的代码单元数吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step7'></a>\n",
    "## 步骤 7: 测试你的算法\n",
    "\n",
    "在这个部分中，你将尝试一下你的新算法！算法认为__你__看起来像什么类型的狗？如果你有一只狗，它可以准确地预测你的狗的品种吗？如果你有一只猫，它会将你的猫误判为一只狗吗？\n",
    "\n",
    "\n",
    "<a id='question11'></a>  \n",
    "\n",
    "### __问题 11:__\n",
    "\n",
    "在下方编写代码，用至少6张现实中的图片来测试你的算法。你可以使用任意照片，不过请至少使用两张人类图片（要征得当事人同意哦）和两张狗的图片。\n",
    "同时请回答如下问题：\n",
    "\n",
    "1. 输出结果比你预想的要好吗 :) ？或者更糟 :( ？\n",
    "2. 提出至少三点改进你的模型的想法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: 在你的电脑上，在步骤6中，至少在6张图片上运行你的算法。\n",
    "## 自由地使用所需的代码单元数吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意: 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出File -> Download as -> HTML (.html)把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
