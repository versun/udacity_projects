{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迷你项目：动态规划\n",
    "\n",
    "在此 notebook 中，你将自己编写很多经典动态规划算法的实现。\n",
    "\n",
    "虽然我们提供了一些起始代码，但是你可以删掉这些提示并从头编写代码。\n",
    "\n",
    "### 第 0 部分：探索 FrozenLakeEnv\n",
    "\n",
    "请使用以下代码单元格创建 [FrozenLake](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py) 环境的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frozenlake import FrozenLakeEnv\n",
    "\n",
    "env = FrozenLakeEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体将会在 $4 \\times 4$ 网格世界中移动，状态编号如下所示："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 0  1  2  3]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体可以执行 4 个潜在动作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，$\\mathcal{S}^+ = \\{0, 1, \\ldots, 15\\}$ 以及 $\\mathcal{A} = \\{0, 1, 2, 3\\}$。请通过运行以下代码单元格验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(16)\n",
      "Discrete(4)\n",
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# print the state space and action space\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "\n",
    "# print the total number of states and actions\n",
    "print(env.nS)\n",
    "print(env.nA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态规划假设智能体完全了解 MDP。我们已经修改了 `frozenlake.py` 文件以使智能体能够访问一步动态特性。  \n",
    "\n",
    "请执行以下代码单元格以返回特定状态和动作对应的一步动态特性。具体而言，当智能体在网格世界中以状态 1 向左移动时，`env.P[1][0]` 会返回每个潜在奖励的概率和下一个状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(0.3333333333333333, 2, 0.0, False),\n",
       "  (0.3333333333333333, 5, 0.0, True),\n",
       "  (0.3333333333333333, 10, 0.0, False)],\n",
       " 1: [(0.3333333333333333, 5, 0.0, True),\n",
       "  (0.3333333333333333, 10, 0.0, False),\n",
       "  (0.3333333333333333, 7, 0.0, True)],\n",
       " 2: [(0.3333333333333333, 10, 0.0, False),\n",
       "  (0.3333333333333333, 7, 0.0, True),\n",
       "  (0.3333333333333333, 2, 0.0, False)],\n",
       " 3: [(0.3333333333333333, 7, 0.0, True),\n",
       "  (0.3333333333333333, 2, 0.0, False),\n",
       "  (0.3333333333333333, 5, 0.0, True)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个条目的格式如下所示"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob, next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中：\n",
    "- `prob` 详细说明了相应的  (`next_state`, `reward`) 对的条件概率，以及\n",
    "- 如果 `next_state` 是终止状态，则 `done` 是 `True` ，否则是 `False`。\n",
    "\n",
    "因此，我们可以按照以下方式解析 `env.P[1][0]`：\n",
    "$$\n",
    "\\mathbb{P}(S_{t+1}=s',R_{t+1}=r|S_t=1,A_t=0) = \\begin{cases}\n",
    "               \\frac{1}{3} \\text{ if } s'=1, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=0, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=5, r=0\\\\\n",
    "               0 \\text{ else}\n",
    "            \\end{cases}\n",
    "$$\n",
    "\n",
    "你可以随意更改上述代码单元格，以探索在其他（状态、动作）对下环境的行为是怎样的。\n",
    "\n",
    "### 第 1 部分：迭代策略评估\n",
    "\n",
    "在此部分，你将自己编写迭代策略评估的实现。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断估算值是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维numpy数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 在输入策略下的估算值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def policy_evaluation(env, policy, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            Vs = 0\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    Vs += action_prob * prob * (reward + gamma * V[next_state])\n",
    "            delta = max(delta, np.abs(V[s]-Vs))\n",
    "            V[s] = Vs\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将评估等概率随机策略  $\\pi$，其中对于所有 $s\\in\\mathcal{S}$ 和 $a\\in\\mathcal{A}(s)$ ，$\\pi(a|s) = \\frac{1}{|\\mathcal{A}(s)|}$。  \n",
    "\n",
    "请使用以下代码单元格在变量 `random_policy`中指定该策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = np.ones([env.nS, env.nA]) / env.nA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以评估等概率随机策略并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\openai-gym\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_utils import plot_values\n",
    "\n",
    "# evaluate the policy \n",
    "V = policy_evaluation(env, random_policy)\n",
    "\n",
    "plot_values(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_13_0.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保你的 `policy_evaluation` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import check_test\n",
    "\n",
    "check_test.run_check('policy_evaluation_check', policy_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 2 部分：通过 $v_\\pi$ 获取 $q_\\pi$\n",
    "\n",
    "在此部分，你将编写一个函数，该函数的输入是状态值函数估值以及一些状态 $s\\in\\mathcal{S}$。它会返回输入状态 $s\\in\\mathcal{S}$ 对应的**动作值函数中的行**。即你的函数应同时接受输入 $v_\\pi$ 和 $s$，并针对所有 $a\\in\\mathcal{A}(s)$ 返回 $q_\\pi(s,a)$。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `s`：这是环境中的状态对应的整数。它应该是在 `0` 到 `(env.nS)-1`（含）之间的值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `q`：这是一个一维 numpy 数组，其中 `q.shape[0]` 等于动作数量 (`env.nA`)。`q[a]` 包含状态 `s` 和动作 `a` 的（估算）值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_from_v(env, V, s, gamma=1):\n",
    "    q = np.zeros(env.nA)\n",
    "    for a in range(env.nA):\n",
    "        for prob, next_state, reward, done in env.P[s][a]:\n",
    "            q[a] += prob * (reward + gamma * V[next_state])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请运行以下代码单元格以输出上述状态值函数对应的动作值函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action-Value Function:\n",
      "[[0.0147094  0.01393978 0.01393978 0.01317015]\n",
      " [0.00852356 0.01163091 0.0108613  0.01550788]\n",
      " [0.02444514 0.02095298 0.02406033 0.01435346]\n",
      " [0.01047649 0.01047649 0.00698432 0.01396865]\n",
      " [0.02166487 0.01701828 0.01624865 0.01006281]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05433538 0.04735105 0.05433538 0.00698432]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.01701828 0.04099204 0.03480619 0.04640826]\n",
      " [0.07020885 0.11755991 0.10595784 0.05895312]\n",
      " [0.18940421 0.17582037 0.16001424 0.04297382]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.08799677 0.20503718 0.23442716 0.17582037]\n",
      " [0.25238823 0.53837051 0.52711478 0.43929118]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros([env.nS, env.nA])\n",
    "for s in range(env.nS):\n",
    "    Q[s] = q_from_v(env, V, s)\n",
    "print(\"Action-Value Function:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `q_from_v` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('q_from_v_check', q_from_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 3 部分：策略改进\n",
    "\n",
    "在此部分，你将自己编写策略改进实现。 \n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "\n",
    "请完成以下代码单元格中的函数。建议你使用你在上文实现的 `q_from_v` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(env, V, gamma=1):\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    for s in range(env.nS):\n",
    "        q = q_from_v(env, V, s, gamma)\n",
    "        \n",
    "        # OPTION 1: construct a deterministic policy \n",
    "        # policy[s][np.argmax(q)] = 1\n",
    "        \n",
    "        # OPTION 2: construct a stochastic policy that puts equal probability on maximizing actions\n",
    "        best_a = np.argwhere(q==np.max(q)).flatten()\n",
    "        policy[s] = np.sum([np.eye(env.nA)[i] for i in best_a], axis=0)/len(best_a)\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_improvement` 函数满足上文列出的要求（具有三个输入、一个输出，并且没有更改输入参数的默认值）。\n",
    "\n",
    "在继续转到该 notebook 的下个部分之前，强烈建议你参阅 **Dynamic_Programming_Solution.ipynb** 中的解决方案。该函数有很多正确的实现方式！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('policy_improvement_check', policy_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 4 部分：策略迭代\n",
    "\n",
    "在此部分，你将自己编写策略迭代的实现。该算法会返回最优策略，以及相应的状态值函数。\n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断策略评估步骤是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。强烈建议你使用你在上文实现的 `policy_evaluation` 和 `policy_improvement` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def policy_iteration(env, gamma=1, theta=1e-8):\n",
    "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        V = policy_evaluation(env, policy, gamma, theta)\n",
    "        new_policy = policy_improvement(env, V)\n",
    "        \n",
    "        # OPTION 1: stop if the policy is unchanged after an improvement step\n",
    "        if (new_policy == policy).all():\n",
    "            break;\n",
    "        \n",
    "        # OPTION 2: stop if the value function estimates for successive policies has converged\n",
    "        # if np.max(abs(policy_evaluation(env, policy) - policy_evaluation(env, new_policy))) < theta*1e2:\n",
    "        #    break;\n",
    "        \n",
    "        policy = copy.copy(new_policy)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。最优状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "**将该最优状态值函数与此 notebook 第 1 部分的状态值函数进行比较**。_最优状态值函数一直都大于或等于等概率随机策略的状态值函数吗？_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
      "[[1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.5  0.   0.5  0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the optimal policy and optimal state-value function\n",
    "policy_pi, V_pi = policy_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_pi,\"\\n\")\n",
    "\n",
    "plot_values(V_pi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_29_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_iteratio` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('policy_iteration_check', policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 5 部分：截断策略迭代\n",
    "\n",
    "在此部分，你将自己编写截断策略迭代的实现。  \n",
    "\n",
    "首先，你将实现截断策略评估。你的算法应该有五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_evaluation(env, policy, V, max_it=1, gamma=1):\n",
    "    num_it=0\n",
    "    while num_it < max_it:\n",
    "        for s in range(env.nS):\n",
    "            v = 0\n",
    "            q = q_from_v(env, V, s, gamma)\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                v += action_prob * q[a]\n",
    "            V[s] = v\n",
    "        num_it += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，你将实现截断策略迭代。你的算法应该接受五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_iteration(env, max_it=1, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        policy = policy_improvement(env, V)\n",
    "        old_V = copy.copy(V)\n",
    "        V = truncated_policy_evaluation(env, policy, V, max_it, gamma)\n",
    "        if max(abs(V-old_V)) < theta:\n",
    "            break;\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "请实验不同的 `max_it` 参数值。始终都能获得最优状态值函数吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
      "[[1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.5  0.   0.5  0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy_tpi, V_tpi = truncated_policy_iteration(env, max_it=2)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_tpi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_tpi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_37_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有四个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('truncated_policy_iteration_check', truncated_policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 6 部分：值迭代\n",
    "\n",
    "在此部分，你将自己编写值迭代的实现。\n",
    "\n",
    "你的算法应该接受三个输入参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。 \n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            v = V[s]\n",
    "            V[s] = max(q_from_v(env, V, s, gamma))\n",
    "            delta = max(delta,abs(V[s]-v))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    policy = policy_improvement(env, V, gamma)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_vi, V_vi = value_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_vi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_43_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('value_iteration_check', value_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-gym",
   "language": "python",
   "name": "openai-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
